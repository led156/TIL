<img width="478" alt="image" src="https://github.com/led156/TIL/assets/67251510/6c1a0e09-f242-4c3d-8cb3-13118d727b1a">
<img width="392" alt="image" src="https://github.com/led156/TIL/assets/67251510/6c43f756-145a-47ac-a4be-d8d42b9a5cb4">


# 5.1. 워크플로 관리
## [기초 지식] 워크플로 관리
- 워크플로 관리(workflow management) : 정형적인 업무 프로세스를 원활하게 진행하기 위한 구조
  + 해당 구조는 배치 처리 실행에도 유용하여 데이터 처리 현장에서도 자주 이용됨.

### 워크플로 관리 도구
- 워크플로 관리 도구의 주요 역할
  + 정기적으로 태스크를 실행하기
  + 비정상적인 상태를 감지하여 그것에 대한 해결을 돕기

|이름|종류|개발사|
|---|---|---|
|Aiflow(에어플로우)|스크립트 형|Airbnb|
|Azkaban(아즈카반)|선언형|LinkedIn|
|Digdag(디그더그)|선언형|트레주어 데이터|
|Luigi(루이지)|스크립트 형|Spotify|
|Oozie(우지)|선언 형|Apache|

### 워크플로 관리 도구와 태스크
- 태스크(Task) : 실행되는 개별처리
- 데이터 파이프라인의 실행 과정에선 데이터를 잇달아 이동하면서 정해진 태스크를 반복함.
<img width="595" alt="image" src="https://github.com/led156/TIL/assets/67251510/115f3e48-c59c-4beb-a923-3f708249b3b0">

### 기본 기능과 빅데이터에서 요구되는 기능
- 워크플로 전용 도구를 사용하는 이유는 태스크 실행에 실패했을 때를 대비해서이다.
  + 데이터 파이프라인이 복잡해지거나, 태스크 수가 증가하면 실패한 태스크를 다시 실행하는 것조차 어려워짐.
- 워크플로 관리 도구의 주요 기능
  + 태스크를 정기적인 스케줄로 실행하고 그 결과 통지하기
  + 태스크 간의 의존 관계를 정하고, 정해진 순서대로 빠짐없이 실행하기
  + 태스크의 실행 결과를 보관하고, 오류 발생 시에는 재실행할 수 있도록 하기
- 이런 기본 기능과, Hadoop에서의 잡(Job)을 손쉽게 호출하거나 집계 결과를 데이터 마트에 기록하는 기능을 제공하는 등 데이터 파이프라인의 모든 태스크를 일원 관리하기 쉽게 한 것.


### 선언 형과 스크립트 형
- 선언형(declarative) 도구
  + XML/YAML 등의 서식으로 워크플로를 기술하는 타입
  + 미리 제공된 기능만 이용할 수 있음
    * 범위 안이라면 최소한의 기술로 태스크를 정의할 수 있음.
    * 누가 작성해도 동일한 워크플로가 되기 때문에 유지 보수성이 높음.
  + 동일 쿼리를 파라미터만 바꾸어 실행하거나, 단순 반복적으로 자동 생성하는 경우에도 이용됨.
- 스크립트 형(scripting) 도구
  + 스크립트 언어로 워크플로를 정의하는 타입
  + 태스크의 정의를 프로그래밍 가능 (유연성 높음)
    * 변수, 제어 구문이 사용 가능하기 때문
  + 데이터 처리를 태스크 안에서 실행하는 것도 가능
  + 예시) 파일의 문자 코드를 변환하면서 서버에 업로드하는 식의 태스크
- 각 태스크에서 나누어 사용하는 것도 하나의 방법이다.
  + ETL 프로세스 = 스크립트 형 도구 / SQL의 실행 = 선언형 도구 / ...
  + 데이터 수집 과정에서는 스크립트 처리가 필요한 경우가 많아 스크립트 형의 도구를 사용
  + 데이터를 모아 두면 정형적인 처리만 하므로, 이후 선언형 도구를 사용
 
## 오류로부터의 복구 방법 먼저 생각하기
- 빅데이터 취급시 발생하는 오류에 대한 대처 방법을 결정해두어야 함.
  + 네트워크의 일시적 장애나 하드웨어 장애
  + 스토리지의 용량 부족
  + 쿼리 증가에 따른 성능 부족
  + 등 ..
 
### 복구와 플로우의 재실행
- 오류
  + 몇 차례 반복하면 성공하는 것 (예시:통신 오류)
  + 몇 차례 반복해도 실패하는 것 (예시:인증 오류)
- 오류에는 수많은 가능성이 있으므로 기본적으로 오류로부터 자동 회복할 수 있다는 점을 고려하지 않고 설계한다.
- 대신 수작업에 의한 '복구(recovery)'를 전제로 태스크를 설계함.
  + 실패한 태스크는 모두 기록하여 나중에 재실행할 수 있도록 함. (플로우, 파라미터를 자동으로 기록함)
- 플로우(flow) : 워크플로 관리 도구에 의해 실행되는 일련의 태스크
  + 각 플로우에는 실행 시에 고정 파라미터가 부여되어 있음 (일별 배치 처리라면, 특정 날짜가 파라미터가 됨)
  + 동일 플로우에 동일 파라미터를 건네면, 완전히 동일한 태스크가 실행됨.
  + → 실패한 플로우를 나중에 동일하게 재실행할 수 있기 때문. → 재실행하여 복구

### 재시도
- 태스크 단위의 자동적인 '재시도(retry)' : 여러 번 발생하는 오류에 대해 되도록 자동화하여 수작업 없이 복구하고 싶을 것임.
- 재시도 횟수
  + 재시도가 적으면 장애 복구 전에 재시도가 종료하게 되어, 태스크 실행에 실패함
  + 재시도가 많으면 태스크가 실패하지도 않은 것처럼 되기 때문에 중대한 문제가 발생해도 눈치채지 못함
  + 이상적 : 전혀 재시도 없이 모든 오류를 통지하는 것이 좋음.
- 예기치 않은 오류에 대해 수작업으로 복구함
  + 문제에 대해 확인하고, 태스크의 재시도로 대처하는 것이 아니라 올바른 문제 해결 방법을 찾도록 함.

### 백필
- 백필(backfill) : 플로우 전체를 처음부터 다시 실행하는 것
  <img width="594" alt="image" src="https://github.com/led156/TIL/assets/67251510/6d83ea4a-49cd-4dff-be6e-d6262a6e2c6f">

  + 파라미터에 포함된 일시를 순서대로 바꿔가면서 일정 기간의 플로우를 연속해서 실행하는 구조
  + 태스크의 실패가 며칠 동안이나 계속된 후에 이를 모두 모아 재실행하고 싶을 때나 / 새롭게 만든 워크플로를 과거로 거슬러 올라가 실행하고 싶은 경우에 사용
 
- 백필에 의해 대량 태스크를 실행할 때 성능상의 주의가 필요함
  + 예시) 새롭게 일별 플로우를 작성했을 때.
    * 백필로 과거 30일 데이터를 처리하려고 하면, 하루의 30배나 되는 데이터를 한 번에 처리하려고 하면 큰 부하가 걸림
    * 따라서 평소라면 일어나지 않을 오류가 대량 발생할 수도...

- 대규모 백필을 실시할 땐 자동적인 재시도는 모두 무효로, 오류는 모두 통지하도록 한다.
  + 조금씩 백필을 실행하여 어떤 오류가 발생하는지 확인하고, 오류가 잦다면 실행 속도를 낮춰 부하를 떨어뜨려야 함.
  + 마지막에 오류가 난 태스크만을 재실행하면 모든 백필이 완료.
 
## 멱등한 조작으로 태스크를 기술하기
- 복구의 전제로써 기억해야 할 것은 재실행의 안전성
  + 태스크 도중 실패했을 때 도중 경과가 남아 있으면, 태스크 재실행에 의해 데이터가 혼재하게 됨
  + 따라서 각 태스크는 원칙적으로 '마지막까지 성공'하거나 '실패하면 아무것도 남지 않음' 둘 중 하나만 존재해야 함.

### 원자성 조작(atomic operation)
- 각 태스크가 시스템에 변경을 가하는 것을 한 번만 할 수 있도록 하는 것 (또는 여러 번의 쓰기를 한 번의 트랜잭션으로 처리)
- 테스크 구현상의 버그 등으로 원자성 조작 직후 문제가 발생하면 이를 보장하지 않을 수도 있다.
  + 예시) 데이터베이스에 데이터를 로드할 때
    * 네트워크 경유의 로드 명령을 발행
    * 직후에 통신이 끊어져 오류가 발생...
    * 이 경우, 로드 명령이 취소될지 아닐지는 데이터베이스를 조작해봐야 앎.
    * 워크플로 관리 도구는 오류 내용에 관여하지 않으므로, 로드 명령이 계속 실행되고 있다면 재시도에서 중복이 발생함.
- 아주 작은 가능성도 허가하지 않을 때는 원자성 조작에 의존한 플로우를 사용해선 안 됨.
  + 적어도 워크플로 관리 도구에 의한 자동적인 재시도는 피하고, 오류의 내용을 반드시 확인한 뒤에 수동으로 복구해야 함.

### 멱등한 조작 : 추가와 치환
- 멱등한 조작(idempotent operation) : 동일한 태스크를 여러 번 실행해도 동일한 결과가 되도록 하는 것
  + 예시) SQL이라면 테이블을 삭제한 후에 다시 만들기가 멱등한 조작의 예임.
  + 만약 도중 오류가 발생해 재실행 해도 다시 한번 테이블을 만드는 부분부터 시작해 중복이 발생X.
- 각 태스크를 어떻게 멱등하게 할 것인지는 이용자의 책임. (원칙은 항상 데이터를 덮어쓰는 것)
  + 추가(append) : 매번 새로운 파일명을 만들 경우
  + 치환(replace) : 동일 파일명으로 덮어쓰는 것
- 추가를 반복하면 데이터가 중복되지만, 치환은 반복해도 결과가 변하지 않음. (따라서 치환은 멱등하다)
  + 즉, 멱등한 태스크를 만들기 위해 태스크에 부여된 파라미터를 잘 이용해 고유의 이름을 생성하고, 여러 번 실행해도 항상 치환이 시행되도록 설계.
  + 그렇지 않으면 멱등한 태스크가 되지 못하므로 자동으로 복구하는 것이 어려운 플로우가 됨.

### 멱등한 추가
- 현실에서는 항상 멱등한 태스크를 구현할 수 없음.
  + 그 날의 데이터만을 INSERT 문으로 기존 테이블에 추가하고 싶을 때, 원자성을 가진 태스크이지만 그대로는 멱등하지 않음 ❶
- 과거 모든 데이터를 치환하면 멱등하지만, 그러면 부하가 커짐.
  + INSERT 앞에서 기존 데이터를 삭제(DELETE)하면 간접적으로 데이터를 치환 : 다만 일부 데이터를 삭제하는 것은 비효율적 & 성능 저하의 요인이 됨.
  + 따라서 '테이블 파티셔닝' 이용. 테이블을 1일/1시간마다 파티션으로 분할하고, 파티션 단위로 치환함. ❷
- → 태스크 단위의 멱등성을 유지하기 위해 테이블 파티셔닝을 도입하여, 시계열 테이블에 데이터가 추가되는 듯한 워크플로 만들기
  + 파티션의 모든 데이터를 삭제하기 : `TRUNCATE` / `INSERT OVERWRITE`
  + 예시) 시스템에 따라 테이블 파티셔닝 구현하기
    * Hive : 표준으로 파티셔닝 대응
    * Amazon Redshift : 파티셔닝의 개념이 없어, `UNION ALL`을 사용한 뷰를 작성해야 함.
    * 태스크를 멱등하게 구성하기 어렵다면, 포기하고 원자성을 지닌 추가만으로 운용.
      - 이 경우, 태스크를 재실행하면 데이터가 중복될 가능성이 있어 자동적인 재시도는 반드시 무효로 처리, 오류 발생 시 수작업으로 복구한다.

<img width="487" alt="image" src="https://github.com/led156/TIL/assets/67251510/a90490ac-3ff2-47b7-be28-28b7b7ee002c">

### 태스크 내부에서의 재시도 제어
- 워크플로 관리 도구는 오류의 종류를 구별하진 않으므로, 예기되는 오류의 경우 태스크 내부에서 명시적으로 대처한다.
- 지수 백오프(exponential backoff)
  + 재시도 횟수를 제어하는 것.
  + 재시도 횟수를 늘림과 동시에, 재시도 간격을 넓혀나가기 위한 방법
  + ```python
    from retry import retry

    # SomeError가 발생한 경우에 재시도를 반복한다. (재시도 간격을 1초, 2초, 4초...로 증가시키면서 최대 7회 실행)
    @retry(exceptions=SomeError, tries=7, delay=1, backoff=2)
    def get_something():
      return make_call('https://api.example.com/...')

    def my_task1():
      res = get_something() # 재시도가 필요한 처리
      ...
    ```
- 타임 아웃
  + 태스크가 아무리 기다려도 끝나지 않아 생기는 문제 (자원 부족으로 실행 시간이 보통보다 늘어난 상태로, 실행이 멈춰 있는 경우)
  + 워크플로 관리 도구 측에서 타임아웃을 지정해, 예상되는 실행 시간과 종료 예정 시간을 설정해 이를 넘으면 통지해줄 수도... 'SLA(Service Level Agreement)'


### 원자성을 지닌 추가
- 복잡한 플로우에서는 하나의 테이블에 몇 번이고 데이터를 써넣을 때가 있음.
  + → 추가를 반복하는 것이 아니라 중간테이블을 만들어 처리한후, 마지막에 목적 테이블에 한 번에 추가하는 것이 안전함. (원자성을 지님)
  + 플로우 실행 중 문제가 발생해도 데이터가 문제가 없고, 중간 테이블을 삭제하여 다시 한번 처음부터 실행할 수도 있다.

  + <img width="404" alt="image" src="https://github.com/led156/TIL/assets/67251510/23a6a566-30cc-4eba-87fe-0889adcf9dc5">
  - ```
    /* 태스크1: 중간 테이블의 작성(치환 → 멱등) */
    DROP TABLE IF EXISTS "t1";
    CREATE TABLE "t1" (...);
    INSERT INTO "t1" ...;
    INSERT INTO "t1" ...;

    /* 태스크2: 대상 테이블에 모아서 써넣는다 */
    INSERT INTO "target_table" /* 멱등하지 않다 */
    SELECT * FROM "t1";
    ```
    
## 워크플로 전체를 멱등으로 하기
<img width="466" alt="image" src="https://github.com/led156/TIL/assets/67251510/d631de9d-5bcf-4e26-bc6b-ab9089e35871">

- 데이터 파이프라인을 안정적으로 운용하기 위해 포함된 태스크나 플로우를 가능한 멱등으로 해야 함. (멱등이 아니면 재시도 시에 데이터 중복의 가능성이 있음)
  + 데이터 수집(Data Ingestion) 파이프라인 : 테이블 파티셔닝을 도입 → 파티션 단위의 치환이 가능
    * 벌크 형 데이터 전송에 대해서도 워크플로 관리 도구에서 날짜, 시간을 파라미터로 전달해 치환 형의 태스크를 구현할 수 있음.
  + 데이터 마트 구축 : 추가는 삼가고 테이블마다 치환.
    * 과정에서 만들어진 중간 테이블도 가능한 한 치환하는 것이 바람직하지만, 성능상의 이유 등으로 추가해야 할 경우도 있음.
- 한 번 성공한 태스크를 취소해 다시 한 번 재실행하고 싶을 때 (데이터 자체에 문제가 발견돼 수정하는 경우)
  + 추가가 포함되어 있으면 안전한 재실행이 불가능함.
  + 재실행 안전성을 높이기 위해, 각 플로우가 전체로서 멱등하게 되도록 구현해야 함.
    * 처음에 중간 테이블을 초기화하는 태스크를 실행하고, 다음부터 추가의 태스크를 계속 실행.
    * 그렇게 하면 플로우 전체를 처음부터 재실행해도 안전함.
    * 모든 플로우가 그런 구현이 되어 있다면, 안심하고 워크플로를 재실행할 수 있음.
  

## 태스크 큐 : 자원의 소비량 컨트롤하기
- 외부 시스템의 부하 컨트롤 : 워크플로 관리 도구의 역할
  + 태스크의 크기나 동시 실행 수를 변화 → 자원의 소비량을 조정하여 모든 태스크가 원활하게 실행되도록 하기
- 예시 상황) 파일 서버로부터 분산 스토리지로의 파일 전송
  + 2메가바이트의 압축이 안 된 텍스트 파일이 1만 개 = 합계 20기가바이트.
  + 하나의 파일을 압축해서 전송하는 데 5초.
  + 이를 단순히 1만 번 반복하면 약 14시간이 걸림
1. 병렬화 고려
   - 데이터 전송에 8코어 서버를 이용
   - 하나의 파일을 하나의 태스크로 고려하자.
     + 각 태스크는 파일 서버로부터 파일을 추출, 압출하고 분산 스토리지로 전송함.
     + 이런 절차는 셀 스크립트화하여 워크플로 관리 도구 안에서 호출 가능
   - 이 경우 파일 수만큼 태스크를 실행해야 함. (대량의 태스크 동시 실행)
   - 잡 큐/태스크 큐 : 모든 태스크를 큐에 저장하여 일정 수 워커 프로세스가 그것을 순서대로 꺼내면서 병렬화를 실현
     <img width="435" alt="image" src="https://github.com/led156/TIL/assets/67251510/28d72e2b-5587-42ff-8166-94160a0a353f">

### 병목 현상의 해소
- 워커 수를 늘리면 실행 속도를 높일 수 있음.
- 다만 워커를 너무 증가시키면, 어디선가 병목 현상이 발생해 성능 향상 한계점이 도달하거나 오류가 발생함.
  + 내부적인 요인
    |증상|대책|
    |---|---|
    |CPU 사용률 100%|CPU 코어 수를 늘린다. 서버를 증설한다.|
    |메모리 부족|메모리를 증설한다. 스왑 디스크를 추가한다. 태스크를 작게 분할한다.|
    |디스크 넘침|각 태스크가 임시 파일을 삭제하고 있는지 확인한다. 디스크를 증설한다.|
    |디스크 I/O의 한계|SSD 등의 고속 디스크를 사용한다. 여러 디스크로 분산한다.|
    |네트워크 대역의 한계|고속 네트워크를 사용한다. 데이터의 압축률을 높인다.|
    |통신 오류나 타임 아웃|시스템 상의 한계일 가능성이 있다. 서버를 분리한다.|
  + 외부적인 요인 : 문제를 제거할 수 없음.
    * 예시 : 파일 복사에서 오류가 발생한다면, 파일 서버 측의 성능 한계일수도. 따라서 워커를 줄여 해결해야 함.
    * 예시2 : 분산 스토리지로의 쓰기 빈도가 너무 높아서 발생한다면, 쓰기 빈도를 줄이도록.


### 태스크 수의 적정화
- 하나의 파일 전송을 하나의 태스크로 고려하지 않고, 파일을 모아서 하나의 태스크로 처리한다면?
  + 작은 태스크를 다수 실행하면 오버헤드가 커지기 때문.
- 각 태스크를 지정된 시간의 데이터를 모아서 처리하도록 구현
  + 예시 : 파일이 1년 걸려 만들어진다면, 태스크를 1일마다 나눠 생성되는 태스크 수를 365개까지 줄인다.
- 태스크를 크게 하면,
  + 작은 파일을 모아서 하나의 파일로 하거나
  + 여러 파일을 한 번에 업로드하는 명령어를 사용할 수 있다.
- 이런 태스크를 좀 더 많은 워커로 동시에 실행해 전체로서 처리 효율을 최대화하는 조합을 찾자.
- 정리 (워크플로 관리 도구의 역할)
  1. 태스크가 너무 클 경우에는 나누고, 너무 작을 경우에는 하나로 모음 : 태스크의 적절한 크기 찾기
  2. 여러 태스크를 동시에 실행하도록 워커 수를 늘려, 한정된 계산 자원을 낭비하지 않기 : 병렬화
  


# 5.2. 배치 형의 데이터 플로우
## MapReduce의 시대는 끝났다
- 분산 시스템 내에서 SQL만으로 데이터를 처리하는 것이 아니라, 프로그래밍 언어로 데이터 파이프라인을 작성하고 싶은 경우도 있음
  + MapReduce를 사용한 데이터 처리에서는 MapReduce 프로그램을 워크플로 태스크로 등록여 복잡한 데이터 처리를 함.
  + 기술 발전으로 현재는 분산 시스템 내부에서 복잡한 데이터 처리를 할 수 있게 됨. : 데이터 플로우(data flow)
 
### MapReduce의 구조
- MapReduce의 대체 : 과거 빅데이터 대표 기술이었지만, 이제는 쓰임이 적어짐.
  + 구글 : 'MillWheel' 프레임워크. Google Cloud Dataflow 내부에서도 이것을 이용
  + Hadoop : 'Tez'
  + & 'Spark'
- MapReduce 개념 : Map과 Reduce를 반복하면서 목적하는 결과를 얻을 때까지 계속해서 데이터를 변환해 나가는 구조
  + <img width="501" alt="image" src="https://github.com/led156/TIL/assets/67251510/7a6ebd04-afe6-434d-870d-186a667e5141">
  + ❷ 파일을 일정 크기로 나누어 작은 데이터인 스플릿(split)을 만듦
  + ❸ 'Map' : 나눈 데이터를 읽어 그중에 포함된 단어를 카운트함 (하나하나의 처리는 독립적이므로 다수의 컴퓨터에 분산)
  + ❸ 'Reduce' : 단어별로 그 수의 합계를 구함 (분산 처리 결과를 집계)
- 구조상 Map-Reduce의 하나의 사이클이 끝나지 않으면 다음 처리로 이동하지 않음 → 복잡한 데이터 처리에서는 대기 시간이 적지 않게 발생함.
  + 특히, 애드 혹 데이터 분석에서 요구되는 지연이 적은 집계가 구현되기 어려움.

## MapReduce를 대신할 새로운 프레임워크 : DAG에 의한 내부 표현
- DAG(directed acyclic graph), 방향성 비순환 그래프
  + 방향성 : 노드와 노드가 화살표로 연결된다
  + 비순환 : 화살표를 아무리 따라가도 동일 노드로는 되돌아오지 않는다

<img width="595" alt="image" src="https://github.com/led156/TIL/assets/67251510/50bff56d-5509-48e4-b88d-bde850f4d48f">

- 일련의 태스크를 DAG에 의한 데이터 구조로 표현
  + 화살표는 태스크의 실행 순서
  + 의존 관계를 유지하면서 실행 순서를 알맞게 정하면 모든 태스크를 빠짐없이 완료할 수 있음
  + → 이를 얼마만큼의 효율로 실행할지만 풀면 됨.
- (MapReduce와 달리) 데이터 플로우에서는 DAG를 구성하는 각 노드가 모두 동시 병행으로 실행됨
  + 처리가 끝난 데이터는 네트워크를 거쳐 차례대로 전달되어 대기시간을 없앰.

### Spark에 있어서의 DAG
- Hive on Tez, Presto 같은 쿼리 엔진에서도 DAG 사용 (SQL로부터 DAG 데이터 구조 자동 생성)
- Spark와 같은 데이터 플로우의 프레임워크에서는 프로그래밍 언어를 사용해 직접 DAG의 데이터 구조를 조립
  ```python
  /* ① 파일로부터 데이터를 읽어 들인다 */
  lines = sc.textFile("sample.txt")
  /* ② 파일의 각 행을 단어로 분해 */
  words = lines.flatMap(lambda line: line.split())
  /* ③ ④ ⑤ 단어마다 카운터를 파일에 출력 */
  ```
  <img width="341" alt="image" src="https://github.com/led156/TIL/assets/67251510/55415357-dcb8-4b25-83a6-50950d8077f1">
- 지연 평가(lazy evaluation) : DAG 프로그래밍 특징
  + 프로그램 각 행은 DAG 데이터 구조를 조립함
  + 여기서 특별히 뭔가를 처리하지는 않음.
  + : DAG를 구축하고 그 후에 명시적/암묵적으로 실행 결과를 요구함에 따라 데이터 처리가 시작됨
- MapReduce와 데이터 플로우 차이
  + MapReduce : Map, Reduce를 하나씩 실행
  + 데이터 플로우 : 데이터 파이프라인 전체를 DAG로 조립하고 나서 실행에 옮김 (내부 스케줄러가 분산 시스템에 효과적인 실행 계획을 세워줌)

## 데이터 플로우와 워크플로를 조합하기
- 데이터 플로우에서 프로그래밍하여, 데이터 입출력을 모두 하나의 DAG로 기술할 수 있게 됨.
- 이때 데이터 플로우와 워크플로 관리 도구의 차이
  + 워크플로 관리 : 태스크를 정기적으로 실행하거나, 실패한 태스크를 기록하여 복구할 수 있다.
    * 데이터 플로우의 프로그램 : 워크플로 일부로서 실행되는 하나의 태스크
    * 분산 시스템 안에서만 실행되는 데이터 처리라면, 하나의 데이터 플로우로 기술 가능
      - 예시) 중간 테이블로 만들고 그것을 다음 쿼리로 읽어 들일 때 이를 다른 태스크로 분리하지 않아도 됨.
    * 이와 달리 분산 시스템 외부와 데이터를 주고 받을 경우에는 오류 복구를 고려해서 워크플로 안에서 실행해야 함.

### 데이터를 읽어들이는 플로우
<img width="364" alt="image" src="https://github.com/led156/TIL/assets/67251510/9cb829c8-7047-44f1-804e-41b96ccda4e8">

- 데이터 플로우로부터 일어 들일 데이터는 성능적으로 안정된 분산 스토리지에 배치하자.
  + 특히 플로우가 완성될 때까지 개발 중에 동일 데이터를 여러 번 읽어들여 테스트하므로 분산 스토리지에 복사된 데이터만을 이용 (하지 않으면 외부의 데이터 소스에 여러 번 접속하게 돼서 성능 문제를 일으킬 수도)

<img width="912" alt="image" src="https://github.com/led156/TIL/assets/67251510/326f0642-010c-4146-93ff-cab66cdbc81f">

- ❶ 외부 데이터 소스에서 데이터를 읽어 들일 때는 벌크 형의 전송 도구로 태스크를 구현
  + 데이터 소스에서의 읽기 속도는 한계가 있어 데이터 플로우 사용에도 불구하고 빨라진다고 단언하지 못함.
  + 따라서 속도보다는 오류의 발생에 대해 확실하게 대처해 복사를 끝내는 것이 좋음. → 따라서, 태스크 실행에 워크플로 관리 도구를 사용하는 것이 적합
- ❷ 데이터 복사를 완료하면, 텍스트 데이터의 가공이나 열 지향 스토리지로의 변환 등 부하가 큰 처리는 데이터 플로우로서 실행 가능함.
  + 이까지 하나의 태스크로 구현하면, 정기적으로 데이터를 읽어 들이기 위한 워크플로가 완성됨.


### 데이터를 써서 내보내는 플로우
- 데이터 집계 결과를 외부 시스템에 써서 내보낼 때.
- 데이터 플로우 안에서 대량의 데이터를 외부에 전송하는 것은 피하자.
  + 쓰기 작업에 오랜 시간이 걸리면, 기다려도 완료되지 않고 자원을 계속해서 소비되거나, 최악에는 쓰기 작업에 실패하여 처음부터 데이터 처리를 재실행해야 할 수도 있음.
 
<img width="880" alt="image" src="https://github.com/led156/TIL/assets/67251510/b00b1be1-6663-442e-bc4f-ab7072b0a4e1">

- ❶ 데이터 플로우 출력은 CSV 파일과 같이 취급하기 쉬운 형식으로 변환해 분산 스토리지에 써넣음
  + 보관만 끝마치면 데이터 플로우의 역할을 끝. 이어서 다음 태스크를 실행
- ❷ 워크플로가 벌크 형의 전송 도구를 사용하여 태스크를 구현하거나 외부 시스템 쪽에서 파일을 읽어 들이도록 지시함
  + 예시) 데이터 마트로 MPP 데이터베이스를 이용한다면, 분산 스토리지로부터 파일을 로드하는 명령어를 발행 가능


## 데이터 플로우와 SQL을 나누어 사용하기
- 데이터 입출력에 더하여 SQL에 의한 쿼리의 실행까지를 조합시킴으로써 배치형의 데이터 파이프라인이 완성됨
  + 모든 처리를 데이터 플로우로 구현하고 싶은 경우는 별개로 하고, 데이터 분석을 목적으로 할 경우에는 SQL로 쿼리를 실행시키는 일이 많을 것임
  + 이를 호출하는 것도 워크플로의 업무

 <img width="353" alt="image" src="https://github.com/led156/TIL/assets/67251510/93f1e752-9653-4d51-857f-4f8c04806cc7">

    
- ❶ '데이터 웨어하우스와 파이프라인' : SQL을 MPP 데이터베이스에서 실행하는 경우
  + 데이터 플로우 : 로드되는 데이터를 만듦
    * 비구조화 데이터를 가공하여 CSV 파일 등을 만들어 분산 스토리지에 써넣는다.
  + 워크플로 : 이후 태스크 실행이나 SQL에 의한 쿼리의 실행
  
- ❷ '데이터마트의 파이프라인' : 분산 시스템상의 쿼리 엔진에서 실행하는 경우
  + 데이터 플로우 : 구조화 데이터를 만듦
    * 분산 스토리지 상의 데이터를 매일 반복되는 배치로 가공하여 열 지향의 스토리지 형식으로 보관
  + 워크플로 : 쿼리 엔진을 사용한 SQL 실행 / 결과를 데이터 마트에 써서 내보냄

### 대화식 플로우
<img width="365" alt="image" src="https://github.com/led156/TIL/assets/67251510/6ccc3663-5c0b-4dea-bd02-dca14b3270df">

- 애드 혹 데이터 분석 : 많은 데이터 처리를 수작업으로 시행해, 워크플로가 필요하지 않음
- 다만 구조화되어 있지 않은 데이터를 애드 혹으로 분석할 때는 데이터 플로우가 매우 유용.
  + 로우 데이터(원시 데이터)에 직접 접속하여 스크립트 언어를 사용해 그 자리에서 데이터를 가공, 집계
  + 데이터를 구조화하는 부분까지 끝내면 그 후의 집계는 고속 처리가 가능 (쿼리 엔진에 의한 SQL 실행과 비교해도 손색이 없는 처리 속도)
- 분석하고 싶은 데이터가 이미 구조화되어 있는 경우에 쿼리 엔진을 사용해 참조함.
  + 커맨드라인(command line)/노트북 안에서 SQL을 실행하거나, 시각화 도구와 쿼리 엔진을 직접 접속하는 경우도 있음 (ODBC, JDBC 드라이버 사용)
  + 단, 쿼리 엔진, 시간화 도구와의 조합이 무수히 많으므로 안정적인 접속을 못 할 수도 있음.. 안정적인 워크플로 운용을 위해서는 RDB와 MPP 데이터베이스를 데이터 마트로 하는 것이 좋다.

# 5.3. 스트리밍 형의 데이터 플로우
## 배치 처리와 스트림 처리로 경로 나누기
- 배치 처리 중심 데이터 파이프라인의 단점 : 데이터가 분석할 수 있게 될 때까지 시간이 걸림.
  + 집계 효율을 높이기 위해 열 지향 스토리지를 만드려다보면, 데이터를 모아서 변환하는 데 일정 시간이 필요함.
  + 보다 실시간에 가까운 데이터 처리에서는 이런 과정을 모두 생략한 파이프라인을 만듦.
- '실시간' : 이벤트 발생에서 몇 초 후에는 결과를 알 수 있는 것
  + 예를 들어 1시간 후에 알아도 된다면, (스트림 처리 대신) 배치 처리로도 할 수 있음.
  + 스트림 처리를 도입하는 것은 민첩성이 요구되는 경우로 한정됨.
    |명칭|설명|
    |---|---|
    |시스템 모니터링|서버와 네트워크의 상태를 감시하고, 그 시간 추이를 그래프로 표시한다.|
    |로그 관리 시스템|운영체제(OS)의 시스템 이벤트나 로그 파일을 검색해서 비정상적인 상태라면 경고를 생성한다.|
    |복합 이벤트 처리(CEP, Complex Event Processing)|다수의 업무 시스템으로부터 보내온 이벤트 데이터를 자동 처리한다.|
- 배치 처리와 스트림 처리
  <img width="914" alt="image" src="https://github.com/led156/TIL/assets/67251510/f4520a35-a090-4f97-86af-17c5514d8553">

  + 배치 처리 : 실시간 메시지 전달 방식으로 메시지 플로우를 중심으로 하는 데이터 흐룸 중, 받은 데이터를 분산 스토리지에 보관하는 부분부터 시작
    * 대체로 1년 이상의 장기적인 데이터 분석을 예상한 스토리지를 구축
    * 그래서 모아둔 데이터를 한 번에 처리하지 않으면 효율이 떨어지므로, 1시간마다 비교적 큰 단위로 데이터를 처리함
    * → 배치 처리의 사이클이 올 때까지는 데이터를 볼 수 없어 실시간 집계에는 적합하지 않음
  + 스트림 처리(streaming processing) : 분산 스토리지를 거치지 않고 처리를 계속하는 것
    * 실시간성이 우수하지만, 과거의 데이터를 취급하는 데에는 부적합
    * 처리 내용을 변경하면 새롭게 도달한 데이터에는 적용되지만, 이미 처리가 끝난 과거 데이터까지는 변경되지 않음.
  + 배치 처리와 스트림 처리는 서로 결점을 보완하는 관계임.

## 배치 처리와 스트림 처리 통합하기
- DAG에 의한 데이터 플로우 기술
  <img width="616" alt="image" src="https://github.com/led156/TIL/assets/67251510/5b9a2a4e-4cb2-4fd1-8055-8a80268ad6ba">

  + 배치 처리 : 먼저 데이터가 있고, 이를 작게 나눠서 DAG에 흘려 넣음
    * 유한 데이터(bounded data) : 실행 시에 데이터양이 정해지는 것
  + 스트림 처리 : 끊임없이 데이터가 생성되며, 그것이 DAG 안에 흘러들어옴에 따라 처리가 진행됨
    * 무한 데이터(unbounded data) : 제한이 없이 데이터가 보내지는 것
  + 두 경우 다 데이터를 작게 분할해서 DAG에서 실행함
    * 따라서 DAG를 사용한 데이터 플로우에서 프로그래밍을 통해 사용할 수 있다.

### Spark 스트리밍의 DAG
- 원래 Spark는 배치 처리를 위한 분산 시스템이었음
  + 'Spark 스트리밍' 기능이 통합됨으로써 현재는 스트림 처리까지 취급하는 프레임워크가 됨.
  + Spark 스트리밍에서 스트림 처리를 하는 파이썬 스크립트
    ```python
    /* 1초마다 스트림 처리를 한다. */
    sc = SparkContext("local[2]", "NetworkWordCount")
    ssc = StreamingContext(sc, 1)
    /* TCP포트 9999로부터 데이터를 읽어 들인다. */
    lines = ssc.socketTextStream("localhost", 9999)
    /* 입력의 각 행을 단어로 분해한다. */
    words = lines.flatMap(lambda line: line.split())
    /* 단어별 갯수를 콘솔에 출력한다. */
    words.map(lambda word: (word, 1)) \
         .reduceByKey(lambda a, b: a + b) \
         .pprint()
    /* 스트림 처리를 시작한다. */
    ssc.start()
    ```
    * 배치 처리 스크립트와 비교하면, 데이터를 읽고 쓰는 초기화 부분에만 차이가 있음을 알 수 있다. (데이터 처리 중심부 Map, Reduce 처리는 똑같음)
- 데이터 플로우의 장점
  + 배치 처리는 데이터 처리가 끝나면 종료. 스트림 처리는 프로그램을 정지할 때까지 끝없이 실행.
  + 각 처리에서 달성하고 싶은 목적이 다르므로, 실제로는 양쪽에서 같은 코드를 동작시키는 일이 그다지 없을 수도 있음.
  + 그렇지만 이렇게 하나의 프레임워크에서 통합적인 데이터 처리를 기술할 수 있다는 점이 데이터 플로우의 장점

### 스트림 처리에 의한 1차 집계
- 데이터양이 많아 모두를 저장하고 싶지 않은 경우에는 데이터양을 삭감하기 위해 스트림 처리를 사용할 수 있음 → 스트림 처리한 결과만을 보관하여 남겨둔다.
  + 불필요한 데이터가 전송되었다면, 먼저 그것을 제외함으로써 스토리지 사용량을 줄일 수 있음.
  + 1초마다 통곗값만을 기록하고 싶은 경우에는 그 집계를 스트림 처리에 맡길 수 있음.
- 스트림 처리의 결과는 메시지 브로커에 다시 작성해서 재이용할 수 있음.
  <img width="471" alt="image" src="https://github.com/led156/TIL/assets/67251510/0d88b39d-bab2-420b-9850-d6735ecd593a">

  + 삭감된 데이터를 일반 메시지 전송과 마찬가지로 한편에선 배치 처리를 위해 분산 스토리지에 보관
  + 다른 쪽에서는 실시간 보고서를 위해 시계열 데이터베이스 등에 전송

## 스트림 처리의 결과를 배치 처리로 치환하기
- 스트림 처리의 잠재적 두 가지 문제
1. 틀린 결과를 어떻게 수정할 것인가?
   - 과거에 틀린 결과를 수정할 수 없다 (시간을 되돌릴 수 없다)
2. 늦게 전송된 데이터 취급을 어떻게 할 것인가?
   - 메시지 배송에 지연이 생겨 이벤트 시간으로 집계하면 문제가 발생 (부정확해짐)
  + 대처 방법 : 스트림 처리와 별개로 배치 처리를 실행시켜 후자의 결과가 옳다고 하는 것
    * 일별 보고서를 속보 값으로, 월별 보고서를 확정값으로 분류해서 작성하는 식.

### 람다 아키텍처(lambda architecture) : 배치 레이어, 서빙 레이어, 스피드 레이어
<img width="691" alt="image" src="https://github.com/led156/TIL/assets/67251510/b817bf66-2b63-4dc6-8c91-d9fd61de69a0">

- 배치 레이어(batch layer) : 모든 데이터는 반드시 해당 레이어에서 처리한다.
  + 과거 데이터를 장기적인 스토리지에 축적하고, 여러 번이고 다시 집계할 수 있게 한다.
  + 배치 레이어는 대규모 배치 처리를 실행할 수 있는 반면에, 1회 처리에는 긴 시간이 걸린다.
- 서빙 레이어(serving layer) : 배치 처리 결과는 해당 레이어를 통해서 접근한다.
  + 응답이 빠른 데이터베이스를 설치하여 집계 결과를 바로 추출한다.
  + 배치 뷰(batch view) : 서빙 레이어에서 얻어진 결과. 정기적으로 업데이트되지만, 실시간 정보를 얻을 수 없다.
- 스피드 레이어(speed layer) : 다른 경로로 스트림 처리를 하기 위한 레이어이다.
  + 실시간 뷰(realtime view) : 스피드 레이어에서 얻은 결과. 배치 뷰가 업데이트될 동안만 이용되고, 오래된 데이터는 순서대로 삭제된다.

- 마지막으로 배치 뷰와 실시간 뷰 모드를 조합시키는 형태로 쿼리를 실행함
  + 최근 24시간의 집계는 실시간 뷰, 그 외 이전 데이터는 배치 뷰를 사용해서 → 배치 처리와 스트림 처리의 결점 보완
- 실시간 뷰의 결과는 자중에 배치 뷰로 치환됨.
  + 스트림 처리 결과는 일시적으로 사용되고, 잠시 기다리면 배치 처리에 의해 올바른 결과를 얻게 됨.
  + 따라서 스트림 처리가 정확하지 않아도 길게 보면 문제가 없음.
  + → 배치 처리만 정상작동한다면 스트림 처리를 다시 할 필요가 없음.
 
### 카파 아키텍처(kappa architecture)
- 스피드 레이어와 배치 레이어가 똑같은 처리를 구현하고 있는 람다 아키텍처의 개발 효율을 개선(단순화)한 아키텍처 : 스피드 레이어만 존재
- 메시지 브로커의 데이터 보관 기간을 길게 한다.
  + 문제가 일어나도 메시지 배송 시간을 과거로 다시 설정하면 과거 데이터가 다시 스트림 처리로 들어와 재실행이 이루어짐.
  + 스트림 처리 내용이 멱등으로 되어있으면 출력 데이터가 덮어씌워져 새로운 결과로 다시 쓰임.
  + → 배치 처리 없이 과거 데이터의 일괄 처리를 스트림 처리만으로 할 수 있음.
- 하지만 부하가 높아진다는 단점이 존재.
  + 대량의 과거 데이터가 있으면 아주 큰 계산 자원을 일시적으로 소비하게 됨. (다만 클라우드 서비스 보급화로 인해 자원 확보가 어렵지 않게 됐으므로 이해할 수 있다는 시점)

## 아웃 오브 오더의 데이터 처리 
- 아웃 오브 오더(out of order) : 프로세스 시간과 이벤트 시간이 차이나는 것 (늦게 도달하는 메시지)

### 원래 데이터의 모습은 '이벤트 시간'으로 얻을 수 있다
- 스트림 처리란 기본적으로 프로세스 시간(도달한 순간)에 집계를 시작하므로, 이것이 혼란을 일으킬 수 있음.
  + 따라서 데이터가 처음 생성된 시간, '이벤트 시간'으로 집계해야 올바른 결과를 얻음.

### 이벤트 시간 윈도윙
- 스트림 처리에서 시간을 일정 간격으로 두어 '왼도우(window)'를 만들고 안에서 데이터 집계를 함.
  + 과거 1시간의 이벤트 수 추이를 그래프로 만들고 싶으면, 1분 간격인 60개의 윈도우로 나누어 각각의 윈도우로 이벤트 수를 세게 됨.
- 이벤트 시간 윈도윙(event-time windowing) : 이벤트 시간에 의해 윈도우를 나누는 것
  <img width="822" alt="image" src="https://github.com/led156/TIL/assets/67251510/30dafba8-3a2c-43ec-b3ab-0904e0e3978e">

  + 이벤트 시간으로 보면, 메시지가 배송된 데이터는 무작위 순으로 나열된 아웃 오브 오더 상태임.
  + 따라서 적절히 순서를 바꿔 집계 결과를 업데이트함.
- 과거 이벤트 상태를 일정시간 보관하면서, 데이터가 도달할 때마다 해당하는 윈도우를 재집계함. → 이를 고려하며 DAG 기술

```java
PCollection<KV<String, Integer>> scores = input
  .apply(Window.into(FixedWindows.of(Duration.standardMinutes(2))) // 2분 간격의 윈도우 생성
  .triggering( // 집계 결과를 출력하는 타이밍(트리거)를 설정
    AtWatermark()
      .withEarlyFirings(AtPeriod(Duration.standardMinutes(1)))
      .withLateFirings(AtCount(1))))
  .apply(Sum.integersPerKey());
```


