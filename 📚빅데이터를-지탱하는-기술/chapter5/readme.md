<img width="478" alt="image" src="https://github.com/led156/TIL/assets/67251510/6c1a0e09-f242-4c3d-8cb3-13118d727b1a">

# 5.1. 워크플로 관리
## [기초 지식] 워크플로 관리
- 워크플로 관리(workflow management) : 정형적인 업무 프로세스를 원활하게 진행하기 위한 구조
  + 해당 구조는 배치 처리 실행에도 유용하여 데이터 처리 현장에서도 자주 이용됨.

### 워크플로 관리 도구
- 워크플로 관리 도구의 주요 역할
  + 정기적으로 태스크를 실행하기
  + 비정상적인 상태를 감지하여 그것에 대한 해결을 돕기

|이름|종류|개발사|
|---|---|---|
|Aiflow(에어플로우)|스크립트 형|Airbnb|
|Azkaban(아즈카반)|선언형|LinkedIn|
|Digdag(디그더그)|선언형|트레주어 데이터|
|Luigi(루이지)|스크립트 형|Spotify|
|Oozie(우지)|선언 형|Apache|

### 워크플로 관리 도구와 태스크
- 태스크(Task) : 실행되는 개별처리
- 데이터 파이프라인의 실행 과정에선 데이터를 잇달아 이동하면서 정해진 태스크를 반복함.
<img width="595" alt="image" src="https://github.com/led156/TIL/assets/67251510/115f3e48-c59c-4beb-a923-3f708249b3b0">

### 기본 기능과 빅데이터에서 요구되는 기능
- 워크플로 전용 도구를 사용하는 이유는 태스크 실행에 실패했을 때를 대비해서이다.
  + 데이터 파이프라인이 복잡해지거나, 태스크 수가 증가하면 실패한 태스크를 다시 실행하는 것조차 어려워짐.
- 워크플로 관리 도구의 주요 기능
  + 태스크를 정기적인 스케줄로 실행하고 그 결과 통지하기
  + 태스크 간의 의존 관계를 정하고, 정해진 순서대로 빠짐없이 실행하기
  + 태스크의 실행 결과를 보관하고, 오류 발생 시에는 재실행할 수 있도록 하기
- 이런 기본 기능과, Hadoop에서의 잡(Job)을 손쉽게 호출하거나 집계 결과를 데이터 마트에 기록하는 기능을 제공하는 등 데이터 파이프라인의 모든 태스크를 일원 관리하기 쉽게 한 것.


### 선언 형과 스크립트 형
- 선언형(declarative) 도구
  + XML/YAML 등의 서식으로 워크플로를 기술하는 타입
  + 미리 제공된 기능만 이용할 수 있음
    * 범위 안이라면 최소한의 기술로 태스크를 정의할 수 있음.
    * 누가 작성해도 동일한 워크플로가 되기 때문에 유지 보수성이 높음.
  + 동일 쿼리를 파라미터만 바꾸어 실행하거나, 단순 반복적으로 자동 생성하는 경우에도 이용됨.
- 스크립트 형(scripting) 도구
  + 스크립트 언어로 워크플로를 정의하는 타입
  + 태스크의 정의를 프로그래밍 가능 (유연성 높음)
    * 변수, 제어 구문이 사용 가능하기 때문
  + 데이터 처리를 태스크 안에서 실행하는 것도 가능
  + 예시) 파일의 문자 코드를 변환하면서 서버에 업로드하는 식의 태스크
- 각 태스크에서 나누어 사용하는 것도 하나의 방법이다.
  + ETL 프로세스 = 스크립트 형 도구 / SQL의 실행 = 선언형 도구 / ...
  + 데이터 수집 과정에서는 스크립트 처리가 필요한 경우가 많아 스크립트 형의 도구를 사용
  + 데이터를 모아 두면 정형적인 처리만 하므로, 이후 선언형 도구를 사용
 
## 오류로부터의 복구 방법 먼저 생각하기
- 빅데이터 취급시 발생하는 오류에 대한 대처 방법을 결정해두어야 함.
  + 네트워크의 일시적 장애나 하드웨어 장애
  + 스토리지의 용량 부족
  + 쿼리 증가에 따른 성능 부족
  + 등 ..
 
### 복구와 플로우의 재실행
- 오류
  + 몇 차례 반복하면 성공하는 것 (예시:통신 오류)
  + 몇 차례 반복해도 실패하는 것 (예시:인증 오류)
- 오류에는 수많은 가능성이 있으므로 기본적으로 오류로부터 자동 회복할 수 있다는 점을 고려하지 않고 설계한다.
- 대신 수작업에 의한 '복구(recovery)'를 전제로 태스크를 설계함.
  + 실패한 태스크는 모두 기록하여 나중에 재실행할 수 있도록 함. (플로우, 파라미터를 자동으로 기록함)
- 플로우(flow) : 워크플로 관리 도구에 의해 실행되는 일련의 태스크
  + 각 플로우에는 실행 시에 고정 파라미터가 부여되어 있음 (일별 배치 처리라면, 특정 날짜가 파라미터가 됨)
  + 동일 플로우에 동일 파라미터를 건네면, 완전히 동일한 태스크가 실행됨.
  + → 실패한 플로우를 나중에 동일하게 재실행할 수 있기 때문. → 재실행하여 복구

### 재시도
- 태스크 단위의 자동적인 '재시도(retry)' : 여러 번 발생하는 오류에 대해 되도록 자동화하여 수작업 없이 복구하고 싶을 것임.
- 재시도 횟수
  + 재시도가 적으면 장애 복구 전에 재시도가 종료하게 되어, 태스크 실행에 실패함
  + 재시도가 많으면 태스크가 실패하지도 않은 것처럼 되기 때문에 중대한 문제가 발생해도 눈치채지 못함
  + 이상적 : 전혀 재시도 없이 모든 오류를 통지하는 것이 좋음.
- 예기치 않은 오류에 대해 수작업으로 복구함
  + 문제에 대해 확인하고, 태스크의 재시도로 대처하는 것이 아니라 올바른 문제 해결 방법을 찾도록 함.

### 백필
- 백필(backfill) : 플로우 전체를 처음부터 다시 실행하는 것
  <img width="594" alt="image" src="https://github.com/led156/TIL/assets/67251510/6d83ea4a-49cd-4dff-be6e-d6262a6e2c6f">

  + 파라미터에 포함된 일시를 순서대로 바꿔가면서 일정 기간의 플로우를 연속해서 실행하는 구조
  + 태스크의 실패가 며칠 동안이나 계속된 후에 이를 모두 모아 재실행하고 싶을 때나 / 새롭게 만든 워크플로를 과거로 거슬러 올라가 실행하고 싶은 경우에 사용
 
- 백필에 의해 대량 태스크를 실행할 때 성능상의 주의가 필요함
  + 예시) 새롭게 일별 플로우를 작성했을 때.
    * 백필로 과거 30일 데이터를 처리하려고 하면, 하루의 30배나 되는 데이터를 한 번에 처리하려고 하면 큰 부하가 걸림
    * 따라서 평소라면 일어나지 않을 오류가 대량 발생할 수도...

- 대규모 백필을 실시할 땐 자동적인 재시도는 모두 무효로, 오류는 모두 통지하도록 한다.
  + 조금씩 백필을 실행하여 어떤 오류가 발생하는지 확인하고, 오류가 잦다면 실행 속도를 낮춰 부하를 떨어뜨려야 함.
  + 마지막에 오류가 난 태스크만을 재실행하면 모든 백필이 완료.
 
## 멱등한 조작으로 태스크를 기술하기
- 복구의 전제로써 기억해야 할 것은 재실행의 안전성
  + 태스크 도중 실패했을 때 도중 경과가 남아 있으면, 태스크 재실행에 의해 데이터가 혼재하게 됨
  + 따라서 각 태스크는 원칙적으로 '마지막까지 성공'하거나 '실패하면 아무것도 남지 않음' 둘 중 하나만 존재해야 함.

### 원자성 조작(atomic operation)
- 각 태스크가 시스템에 변경을 가하는 것을 한 번만 할 수 있도록 하는 것 (또는 여러 번의 쓰기를 한 번의 트랜잭션으로 처리)
- 테스크 구현상의 버그 등으로 원자성 조작 직후 문제가 발생하면 이를 보장하지 않을 수도 있다.
  + 예시) 데이터베이스에 데이터를 로드할 때
    * 네트워크 경유의 로드 명령을 발행
    * 직후에 통신이 끊어져 오류가 발생...
    * 이 경우, 로드 명령이 취소될지 아닐지는 데이터베이스를 조작해봐야 앎.
    * 워크플로 관리 도구는 오류 내용에 관여하지 않으므로, 로드 명령이 계속 실행되고 있다면 재시도에서 중복이 발생함.
- 아주 작은 가능성도 허가하지 않을 때는 원자성 조작에 의존한 플로우를 사용해선 안 됨.
  + 적어도 워크플로 관리 도구에 의한 자동적인 재시도는 피하고, 오류의 내용을 반드시 확인한 뒤에 수동으로 복구해야 함.

### 멱등한 조작 : 추가와 치환
- 멱등한 조작(idempotent operation) : 동일한 태스크를 여러 번 실행해도 동일한 결과가 되도록 하는 것
  + 예시) SQL이라면 테이블을 삭제한 후에 다시 만들기가 멱등한 조작의 예임.
  + 만약 도중 오류가 발생해 재실행 해도 다시 한번 테이블을 만드는 부분부터 시작해 중복이 발생X.
- 각 태스크를 어떻게 멱등하게 할 것인지는 이용자의 책임. (원칙은 항상 데이터를 덮어쓰는 것)
  + 추가(append) : 매번 새로운 파일명을 만들 경우
  + 치환(replace) : 동일 파일명으로 덮어쓰는 것
- 추가를 반복하면 데이터가 중복되지만, 치환은 반복해도 결과가 변하지 않음. (따라서 치환은 멱등하다)
  + 즉, 멱등한 태스크를 만들기 위해 태스크에 부여된 파라미터를 잘 이용해 고유의 이름을 생성하고, 여러 번 실행해도 항상 치환이 시행되도록 설계.
  + 그렇지 않으면 멱등한 태스크가 되지 못하므로 자동으로 복구하는 것이 어려운 플로우가 됨.

### 멱등한 추가
- 현실에서는 항상 멱등한 태스크를 구현할 수 없음.
  + 그 날의 데이터만을 INSERT 문으로 기존 테이블에 추가하고 싶을 때, 원자성을 가진 태스크이지만 그대로는 멱등하지 않음 ❶
- 과거 모든 데이터를 치환하면 멱등하지만, 그러면 부하가 커짐.
  + INSERT 앞에서 기존 데이터를 삭제(DELETE)하면 간접적으로 데이터를 치환 : 다만 일부 데이터를 삭제하는 것은 비효율적 & 성능 저하의 요인이 됨.
  + 따라서 '테이블 파티셔닝' 이용. 테이블을 1일/1시간마다 파티션으로 분할하고, 파티션 단위로 치환함. ❷
- → 태스크 단위의 멱등성을 유지하기 위해 테이블 파티셔닝을 도입하여, 시계열 테이블에 데이터가 추가되는 듯한 워크플로 만들기
  + 파티션의 모든 데이터를 삭제하기 : `TRUNCATE` / `INSERT OVERWRITE`
  + 예시) 시스템에 따라 테이블 파티셔닝 구현하기
    * Hive : 표준으로 파티셔닝 대응
    * Amazon Redshift : 파티셔닝의 개념이 없어, `UNION ALL`을 사용한 뷰를 작성해야 함.
    * 태스크를 멱등하게 구성하기 어렵다면, 포기하고 원자성을 지닌 추가만으로 운용.
      - 이 경우, 태스크를 재실행하면 데이터가 중복될 가능성이 있어 자동적인 재시도는 반드시 무효로 처리, 오류 발생 시 수작업으로 복구한다.

<img width="487" alt="image" src="https://github.com/led156/TIL/assets/67251510/a90490ac-3ff2-47b7-be28-28b7b7ee002c">

### 태스크 내부에서의 재시도 제어
- 워크플로 관리 도구는 오류의 종류를 구별하진 않으므로, 예기되는 오류의 경우 태스크 내부에서 명시적으로 대처한다.
- 지수 백오프(exponential backoff)
  + 재시도 횟수를 제어하는 것.
  + 재시도 횟수를 늘림과 동시에, 재시도 간격을 넓혀나가기 위한 방법
  + ```python
    from retry import retry

    # SomeError가 발생한 경우에 재시도를 반복한다. (재시도 간격을 1초, 2초, 4초...로 증가시키면서 최대 7회 실행)
    @retry(exceptions=SomeError, tries=7, delay=1, backoff=2)
    def get_something():
      return make_call('https://api.example.com/...')

    def my_task1():
      res = get_something() # 재시도가 필요한 처리
      ...
    ```
- 타임 아웃
  + 태스크가 아무리 기다려도 끝나지 않아 생기는 문제 (자원 부족으로 실행 시간이 보통보다 늘어난 상태로, 실행이 멈춰 있는 경우)
  + 워크플로 관리 도구 측에서 타임아웃을 지정해, 예상되는 실행 시간과 종료 예정 시간을 설정해 이를 넘으면 통지해줄 수도... 'SLA(Service Level Agreement)'


### 원자성을 지닌 추가
- 복잡한 플로우에서는 하나의 테이블에 몇 번이고 데이터를 써넣을 때가 있음.
  + → 추가를 반복하는 것이 아니라 중간테이블을 만들어 처리한후, 마지막에 목적 테이블에 한 번에 추가하는 것이 안전함. (원자성을 지님)
  + 플로우 실행 중 문제가 발생해도 데이터가 문제가 없고, 중간 테이블을 삭제하여 다시 한번 처음부터 실행할 수도 있다.

  + <img width="404" alt="image" src="https://github.com/led156/TIL/assets/67251510/23a6a566-30cc-4eba-87fe-0889adcf9dc5">
  - ```
    /* 태스크1: 중간 테이블의 작성(치환 → 멱등) */
    DROP TABLE IF EXISTS "t1";
    CREATE TABLE "t1" (...);
    INSERT INTO "t1" ...;
    INSERT INTO "t1" ...;

    /* 태스크2: 대상 테이블에 모아서 써넣는다 */
    INSERT INTO "target_table" /* 멱등하지 않다 */
    SELECT * FROM "t1";
    ```
    
## 워크플로 전체를 멱등으로 하기
<img width="466" alt="image" src="https://github.com/led156/TIL/assets/67251510/d631de9d-5bcf-4e26-bc6b-ab9089e35871">

- 데이터 파이프라인을 안정적으로 운용하기 위해 포함된 태스크나 플로우를 가능한 멱등으로 해야 함. (멱등이 아니면 재시도 시에 데이터 중복의 가능성이 있음)
  + 데이터 수집(Data Ingestion) 파이프라인 : 테이블 파티셔닝을 도입 → 파티션 단위의 치환이 가능
    * 벌크 형 데이터 전송에 대해서도 워크플로 관리 도구에서 날짜, 시간을 파라미터로 전달해 치환 형의 태스크를 구현할 수 있음.
  + 데이터 마트 구축 : 추가는 삼가고 테이블마다 치환.
    * 과정에서 만들어진 중간 테이블도 가능한 한 치환하는 것이 바람직하지만, 성능상의 이유 등으로 추가해야 할 경우도 있음.
- 한 번 성공한 태스크를 취소해 다시 한 번 재실행하고 싶을 때 (데이터 자체에 문제가 발견돼 수정하는 경우)
  + 추가가 포함되어 있으면 안전한 재실행이 불가능함.
  + 재실행 안전성을 높이기 위해, 각 플로우가 전체로서 멱등하게 되도록 구현해야 함.
    * 처음에 중간 테이블을 초기화하는 태스크를 실행하고, 다음부터 추가의 태스크를 계속 실행.
    * 그렇게 하면 플로우 전체를 처음부터 재실행해도 안전함.
    * 모든 플로우가 그런 구현이 되어 있다면, 안심하고 워크플로를 재실행할 수 있음.
  

## 태스크 큐 : 자원의 소비량 컨트롤하기
- 외부 시스템의 부하 컨트롤 : 워크플로 관리 도구의 역할
  + 태스크의 크기나 동시 실행 수를 변화 → 자원의 소비량을 조정하여 모든 태스크가 원활하게 실행되도록 하기
- 예시 상황) 파일 서버로부터 분산 스토리지로의 파일 전송
  + 2메가바이트의 압축이 안 된 텍스트 파일이 1만 개 = 합계 20기가바이트.
  + 하나의 파일을 압축해서 전송하는 데 5초.
  + 이를 단순히 1만 번 반복하면 약 14시간이 걸림
1. 병렬화 고려
   - 데이터 전송에 8코어 서버를 이용
   - 하나의 파일을 하나의 태스크로 고려하자.
     + 각 태스크는 파일 서버로부터 파일을 추출, 압출하고 분산 스토리지로 전송함.
     + 이런 절차는 셀 스크립트화하여 워크플로 관리 도구 안에서 호출 가능
   - 이 경우 파일 수만큼 태스크를 실행해야 함. (대량의 태스크 동시 실행)
   - 잡 큐/태스크 큐 : 모든 태스크를 큐에 저장하여 일정 수 워커 프로세스가 그것을 순서대로 꺼내면서 병렬화를 실현
     <img width="435" alt="image" src="https://github.com/led156/TIL/assets/67251510/28d72e2b-5587-42ff-8166-94160a0a353f">

### 병목 현상의 해소
- 워커 수를 늘리면 실행 속도를 높일 수 있음.
- 다만 워커를 너무 증가시키면, 어디선가 병목 현상이 발생해 성능 향상 한계점이 도달하거나 오류가 발생함.
  + 내부적인 요인
    |증상|대책|
    |---|---|
    |CPU 사용률 100%|CPU 코어 수를 늘린다. 서버를 증설한다.|
    |메모리 부족|메모리를 증설한다. 스왑 디스크를 추가한다. 태스크를 작게 분할한다.|
    |디스크 넘침|각 태스크가 임시 파일을 삭제하고 있는지 확인한다. 디스크를 증설한다.|
    |디스크 I/O의 한계|SSD 등의 고속 디스크를 사용한다. 여러 디스크로 분산한다.|
    |네트워크 대역의 한계|고속 네트워크를 사용한다. 데이터의 압축률을 높인다.|
    |통신 오류나 타임 아웃|시스템 상의 한계일 가능성이 있다. 서버를 분리한다.|
  + 외부적인 요인 : 문제를 제거할 수 없음.
    * 예시 : 파일 복사에서 오류가 발생한다면, 파일 서버 측의 성능 한계일수도. 따라서 워커를 줄여 해결해야 함.
    * 예시2 : 분산 스토리지로의 쓰기 빈도가 너무 높아서 발생한다면, 쓰기 빈도를 줄이도록.


### 태스크 수의 적정화
- 하나의 파일 전송을 하나의 태스크로 고려하지 않고, 파일을 모아서 하나의 태스크로 처리한다면?
  + 작은 태스크를 다수 실행하면 오버헤드가 커지기 때문.
- 각 태스크를 지정된 시간의 데이터를 모아서 처리하도록 구현
  + 예시 : 파일이 1년 걸려 만들어진다면, 태스크를 1일마다 나눠 생성되는 태스크 수를 365개까지 줄인다.
- 태스크를 크게 하면,
  + 작은 파일을 모아서 하나의 파일로 하거나
  + 여러 파일을 한 번에 업로드하는 명령어를 사용할 수 있다.
- 이런 태스크를 좀 더 많은 워커로 동시에 실행해 전체로서 처리 효율을 최대화하는 조합을 찾자.
- 정리 (워크플로 관리 도구의 역할)
  1. 태스크가 너무 클 경우에는 나누고, 너무 작을 경우에는 하나로 모음 : 태스크의 적절한 크기 찾기
  2. 여러 태스크를 동시에 실행하도록 워커 수를 늘려, 한정된 계산 자원을 낭비하지 않기 : 병렬화
  


# 5.2. 배치 형의 데이터 플로우
## MapReduce의 시대는 끝났다
- 분산 시스템 내에서 SQL만으로 데이터를 처리하는 것이 아니라, 프로그래밍 언어로 데이터 파이프라인을 작성하고 싶은 경우도 있음
  + MapReduce를 사용한 데이터 처리에서는 MapReduce 프로그램을 워크플로 태스크로 등록여 복잡한 데이터 처리를 함.
  + 기술 발전으로 현재는 분산 시스템 내부에서 복잡한 데이터 처리를 할 수 있게 됨. : 데이터 플로우(data flow)
 
### MapReduce의 구조
- MapReduce의 대체 : 과거 빅데이터 대표 기술이었지만, 이제는 쓰임이 적어짐.
  + 구글 : 'MillWheel' 프레임워크. Google Cloud Dataflow 내부에서도 이것을 이용
  + Hadoop : 'Tez'
  + & 'Spark'
- MapReduce 개념 : Map과 Reduce를 반복하면서 목적하는 결과를 얻을 때까지 계속해서 데이터를 변환해 나가는 구조
  + <img width="501" alt="image" src="https://github.com/led156/TIL/assets/67251510/7a6ebd04-afe6-434d-870d-186a667e5141">
  + ❷ 파일을 일정 크기로 나누어 작은 데이터인 스플릿(split)을 만듦
  + ❸ 'Map' : 나눈 데이터를 읽어 그중에 포함된 단어를 카운트함 (하나하나의 처리는 독립적이므로 다수의 컴퓨터에 분산)
  + ❸ 'Reduce' : 단어별로 그 수의 합계를 구함 (분산 처리 결과를 집계)
- 구조상 Map-Reduce의 하나의 사이클이 끝나지 않으면 다음 처리로 이동하지 않음 → 복잡한 데이터 처리에서는 대기 시간이 적지 않게 발생함.
  + 특히, 애드 혹 데이터 분석에서 요구되는 지연이 적은 집계가 구현되기 어려움.

## MapReduce를 대신할 새로운 프레임워크 : DAG에 의한 내부 표현
- DAG(directed acyclic graph), 방향성 비순환 그래프
  + 방향성 : 노드와 노드가 화살표로 연결된다
  + 비순환 : 화살표를 아무리 따라가도 동일 노드로는 되돌아오지 않는다

<img width="595" alt="image" src="https://github.com/led156/TIL/assets/67251510/50bff56d-5509-48e4-b88d-bde850f4d48f">

- 일련의 태스크를 DAG에 의한 데이터 구조로 표현
  + 화살표는 태스크의 실행 순서
  + 의존 관계를 유지하면서 실행 순서를 알맞게 정하면 모든 태스크를 빠짐없이 완료할 수 있음
  + → 이를 얼마만큼의 효율로 실행할지만 풀면 됨.
- (MapReduce와 달리) 데이터 플로우에서는 DAG를 구성하는 각 노드가 모두 동시 병행으로 실행됨
  + 처리가 끝난 데이터는 네트워크를 거쳐 차례대로 전달되어 대기시간을 없앰.

### Spark에 있어서의 DAG
- Hive on Tez, Presto 같은 쿼리 엔진에서도 DAG 사용 (SQL로부터 DAG 데이터 구조 자동 생성)
- Spark와 같은 데이터 플로우의 프레임워크에서는 프로그래밍 언어를 사용해 직접 DAG의 데이터 구조를 조립
  ```python
  /* ① 파일로부터 데이터를 읽어 들인다 */
  lines = sc.textFile("sample.txt")
  /* ② 파일의 각 행을 단어로 분해 */
  words = lines.flatMap(lambda line: line.split())
  /* ③ ④ ⑤ 단어마다 카운터를 파일에 출력 */
  ```
  <img width="341" alt="image" src="https://github.com/led156/TIL/assets/67251510/55415357-dcb8-4b25-83a6-50950d8077f1">
- 지연 평가(lazy evaluation) : DAG 프로그래밍 특징
  + 프로그램 각 행은 DAG 데이터 구조를 조립함
  + 여기서 특별히 뭔가를 처리하지는 않음.
  + : DAG를 구축하고 그 후에 명시적/암묵적으로 실행 결과를 요구함에 따라 데이터 처리가 시작됨
- MapReduce와 데이터 플로우 차이
  + MapReduce : Map, Reduce를 하나씩 실행
  + 데이터 플로우 : 데이터 파이프라인 전체를 DAG로 조립하고 나서 실행에 옮김 (내부 스케줄러가 분산 시스템에 효과적인 실행 계획을 세워줌)

## 데이터 플로우와 워크플로를 조합하기
- 데이터 플로우에서 프로그래밍하여, 데이터 입출력을 모두 하나의 DAG로 기술할 수 있게 됨.
- 이때 데이터 플로우와 워크플로 관리 도구의 차이
  + 워크플로 관리 : 태스크를 정기적으로 실행하거나, 실패한 태스크를 기록하여 복구할 수 있다.
    * 데이터 플로우의 프로그램 : 워크플로 일부로서 실행되는 하나의 태스크
    * 분산 시스템 안에서만 실행되는 데이터 처리라면, 하나의 데이터 플로우로 기술 가능
      - 예시) 중간 테이블로 만들고 그것을 다음 쿼리로 읽어 들일 때 이를 다른 태스크로 분리하지 않아도 됨.
    * 이와 달리 분산 시스템 외부와 데이터를 주고 받을 경우에는 오류 복구를 고려해서 워크플로 안에서 실행해야 함.

### 데이터를 읽어들이는 플로우
<img width="364" alt="image" src="https://github.com/led156/TIL/assets/67251510/9cb829c8-7047-44f1-804e-41b96ccda4e8">

- 데이터 플로우로부터 일어 들일 데이터는 성능적으로 안정된 분산 스토리지에 배치하자.
  + 특히 플로우가 완성될 때까지 개발 중에 동일 데이터를 여러 번 읽어들여 테스트하므로 분산 스토리지에 복사된 데이터만을 이용 (하지 않으면 외부의 데이터 소스에 여러 번 접속하게 돼서 성능 문제를 일으킬 수도)

<img width="912" alt="image" src="https://github.com/led156/TIL/assets/67251510/326f0642-010c-4146-93ff-cab66cdbc81f">

- ❶ 외부 데이터 소스에서 데이터를 읽어 들일 때는 벌크 형의 전송 도구로 태스크를 구현
  + 데이터 소스에서의 읽기 속도는 한계가 있어 데이터 플로우 사용에도 불구하고 빨라진다고 단언하지 못함.
  + 따라서 속도보다는 오류의 발생에 대해 확실하게 대처해 복사를 끝내는 것이 좋음. → 따라서, 태스크 실행에 워크플로 관리 도구를 사용하는 것이 적합
- ❷ 데이터 복사를 완료하면, 텍스트 데이터의 가공이나 열 지향 스토리지로의 변환 등 부하가 큰 처리는 데이터 플로우로서 실행 가능함.
  + 이까지 하나의 태스크로 구현하면, 정기적으로 데이터를 읽어 들이기 위한 워크플로가 완성됨.


### 데이터를 써서 내보내는 플로우
- 데이터 집계 결과를 외부 시스템에 써서 내보낼 때.
- 데이터 플로우 안에서 대량의 데이터를 외부에 전송하는 것은 피하자.
  + 쓰기 작업에 오랜 시간이 걸리면, 기다려도 완료되지 않고 자원을 계속해서 소비되거나, 최악에는 쓰기 작업에 실패하여 처음부터 데이터 처리를 재실행해야 할 수도 있음.
 
<img width="880" alt="image" src="https://github.com/led156/TIL/assets/67251510/b00b1be1-6663-442e-bc4f-ab7072b0a4e1">

- ❶ 데이터 플로우 출력은 CSV 파일과 같이 취급하기 쉬운 형식으로 변환해 분산 스토리지에 써넣음
  + 보관만 끝마치면 데이터 플로우의 역할을 끝. 이어서 다음 태스크를 실행
- ❷ 워크플로가 벌크 형의 전송 도구를 사용하여 태스크를 구현하거나 외부 시스템 쪽에서 파일을 읽어 들이도록 지시함
  + 예시) 데이터 마트로 MPP 데이터베이스를 이용한다면, 분산 스토리지로부터 파일을 로드하는 명령어를 발행 가능


## 데이터 플로우와 SQL을 나누어 사용하기
- 데이터 입출력에 더하여 SQL에 의한 쿼리의 실행까지를 조합시킴으로써 배치형의 데이터 파이프라인이 완성됨
  + 모든 처리를 데이터 플로우로 구현하고 싶은 경우는 별개로 하고, 데이터 분석을 목적으로 할 경우에는 SQL로 쿼리를 실행시키는 일이 많을 것임
  + 이를 호출하는 것도 워크플로의 업무

 <img width="353" alt="image" src="https://github.com/led156/TIL/assets/67251510/93f1e752-9653-4d51-857f-4f8c04806cc7">

    
- ❶ '데이터 웨어하우스와 파이프라인' : SQL을 MPP 데이터베이스에서 실행하는 경우
  + 데이터 플로우 : 로드되는 데이터를 만듦
    * 비구조화 데이터를 가공하여 CSV 파일 등을 만들어 분산 스토리지에 써넣는다.
  + 워크플로 : 이후 태스크 실행이나 SQL에 의한 쿼리의 실행
  
- ❷ '데이터마트의 파이프라인' : 분산 시스템상의 쿼리 엔진에서 실행하는 경우
  + 데이터 플로우 : 구조화 데이터를 만듦
    * 분산 스토리지 상의 데이터를 매일 반복되는 배치로 가공하여 열 지향의 스토리지 형식으로 보관
  + 워크플로 : 쿼리 엔진을 사용한 SQL 실행 / 결과를 데이터 마트에 써서 내보냄

### 대화식 플로우
<img width="365" alt="image" src="https://github.com/led156/TIL/assets/67251510/6ccc3663-5c0b-4dea-bd02-dca14b3270df">

- 애드 혹 데이터 분석 : 많은 데이터 처리를 수작업으로 시행해, 워크플로가 필요하지 않음
- 다만 구조화되어 있지 않은 데이터를 애드 혹으로 분석할 때는 데이터 플로우가 매우 유용.
  + 로우 데이터(원시 데이터)에 직접 접속하여 스크립트 언어를 사용해 그 자리에서 데이터를 가공, 집계
  + 데이터를 구조화하는 부분까지 끝내면 그 후의 집계는 고속 처리가 가능 (쿼리 엔진에 의한 SQL 실행과 비교해도 손색이 없는 처리 속도)
- 분석하고 싶은 데이터가 이미 구조화되어 있는 경우에 쿼리 엔진을 사용해 참조함.
  + 커맨드라인(command line)/노트북 안에서 SQL을 실행하거나, 시각화 도구와 쿼리 엔진을 직접 접속하는 경우도 있음 (ODBC, JDBC 드라이버 사용)
  + 단, 쿼리 엔진, 시간화 도구와의 조합이 무수히 많으므로 안정적인 접속을 못 할 수도 있음.. 안정적인 워크플로 운용을 위해서는 RDB와 MPP 데이터베이스를 데이터 마트로 하는 것이 좋다.

# 5.3. 스트리밍 형의 데이터 플로우



