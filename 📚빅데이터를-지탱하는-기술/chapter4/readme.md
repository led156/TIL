<img width="493" alt="image" src="https://github.com/led156/TIL/assets/67251510/925bdc8e-95ff-458a-a40d-70377f6f9b65">


# 4.1. 벌크 형과 스트리밍 형의 데이터 수집
## 객체 스토리지와 데이터 수집
- 빅데이터는 대부분 확장성이 높은 '분산 스토리지(distributed storage)'에 저장됨.
  <img width="593" alt="image" src="https://github.com/led156/TIL/assets/67251510/d7c9feb9-acb9-4b4a-9c62-1202cfa8d295">

  + 분산 형의 데이터베이스가 이용되는 경우도 있지만, 기본은 대량으로 파일을 저장하기 위해 '객체 스토리지(object storage)'임.
  + Hadoop의 'HDFS', 클라우드 서비스로는 'Amazon S3'
  + 객체 스토리지에서의 파일 읽고 쓰기는 네트워크를 거쳐서 실행함.
    * 내부 처리에 다수의 물리적인 서버와 하드 디스크가 있음.
    * 데이터는 여러 디스크에 복사되기 때문에 일부 하드웨어가 고장나더라도 데이터가 손실되지 않는다.
    * 데이터의 읽고 쓰기를 다수 하드웨어에 분산함으로써 데이터의 양이 늘어나도 성능이 떨어지는 일이 없도록 고안되어 있다.
  + 객체 스토리지의 구조는 데이터양이 많을 때 우수하지만, 소량의 데이터에는 비효율적임에 주의.
    * 예시) 100바이트의 작은 파일을 자주 읽고 쓰는 것은 적합X. 데이터양에 비해 통신 오버헤드가 크기 때문.

### 데이터 수집
- 데이터 수집(data ingesion) : 수집한 데이터를 가공하여 집계 효율이 좋은 분산 스토리지를 만드는 일련의 프로세스. (데이터 수집부터~ 구조화 데이터의 작성, 분산 스토리지에 대한 장기적 저장)
- 빅데이터로 자주 다루는 것은 시간과 함께 생성되는 데이터임 (시계열 데이터)
- 이를 수시로 객체 스토리지에 기록하면 대량의 작은 파일이 생성됨 → 시간이 지남에 따라 성능 저하의 요인이 됨. ⇒ 작은 데이터를 적당히 모아 하나의 큰 파일로 만들어 효율을 높인다.
- 반대로, 지나치게 파일이 커도 문제가 있음.
  + 파일 크기가 증가하면 네트워크 전송에 시간이 걸려 예상치 못한 오류 발생률이 높아짐.
- 단순히 수집보다 나중에 처리하기 쉽도록 준비해 둘 필요가 있음.
  + 객체 스토리지에서 효율적으로 처리할 수 있는 파일 크기는 1MB~1GB 사이이다.

## 벌크 형의 데이터 전송
- 전통적인 데이터 웨어하우스에서 사용.
  + 데이터베이스나 파일 서버/웹 서비스 등에서 각각의 방식(SQL, API 등)으로 정리해 데이터를 추출.
  + 과거 축적된 대량의 데이터 / 기존 데이터를 추출하고 싶을 경우에도 사용.
- 데이터가 처음부터 분산 스토리지에 저장되어 있지 않다면, 데이터 전송을 위한 'ETL 서버'를 설치함.
  <img width="482" alt="image" src="https://github.com/led156/TIL/assets/67251510/427f5d11-d000-4283-bdb6-d10fd573f64f">

  + ELT 서버 : 구조화된 데이터 처리에 적합하고, 데이터 웨어하우스를 위한 ETL 도구 & 오픈 소스의 벌크 전송 도구 또는 손수 작성한 스크립트 등을 사용 가능.

### 파일 사이즈의 적정화는 비교적 간단하다
- ETL 프로세스는 1시간~하루마다 간격으로 정기적 실행을 함 → 파일 사이즈를 자동으로 적정화.
- 그렇게 사용하고 있지 않다면 전송 방법을 검토
  + 예시) 100개의 파일을 전송할 때 100번 전송하는 것이 아닌, 모아서 전송. = 한 번의 전송에 모든 파일을 포함
  + 데이터 양이 많을 때는 단위를 조절해 작은 태스크로 분해. (워크플로 관리 도구 사용)
 
### 데이터 전송의 워크플로
- 데이터 전송의 신뢰성이 중요한 경우에는 벌크형 도구를 주로 사용.
  + 스트리밍형의 경우 데이터 전송 재실행이 쉽지 않음.
  + 벌크형 전송의 장점 → 문제가 발생했을 때 전송을 재실행할 수 있음.
  + ⇒ 과거의 데이터를 빠짐없이 가져오거나, 실패한 작업을 재실행할 것을 고려하면 .. 벌크형 전송으로!
- 벌크 형 데이터 전송은 워크플로 관리 도구와의 궁합이 뛰어남.
  + 정기적인 스케줄 실행/오류 통지등을 워크플로 관리 도구에 맡김.
  + 매일 매일 마스터 데이터 스냅샷 & 신뢰성이 중시되는 과금 데이터 전송 등은 다른 배치 처리와 함께 워크플로의 일부에 포함시키는 것이 좋음 ❓

## 스트리밍 형의 데이터 전송
<img width="607" alt="image" src="https://github.com/led156/TIL/assets/67251510/fbe60b40-af96-4dfd-b59d-c893bc5b1f08">

- 대다수 데이터는 통신 장비 및 소프트웨어에 의해 생성, 그리고 네트워크를 거쳐 전송됨. (웹 브라우저, 모바일 앱, 각종 디바이스 등)
  + 지금 바로 생성되어 어디에도 저장되지 않은 데이터를 바로 전송 : 스트리밍 형 데이터 전송이 필요.
- 이러한 데이터 전송의 공통점
  + 메시지 배송(message delivery) : 다수의 클라이언트에서, 계속해서 작은 데이터가 전송됨.
  + 전송되는 데이터양에 비해 통신을 위한 오버헤드가 큼. → 처리하는 서버의 성능이 높아야 함.
- 보내온 메시지를 저장하는 방법
  1. 작은 데이터 쓰기에 적합한 NoSQL 데이터베이스 : Hive와 같은 쿼리 엔진으로 NoSQL 데이터베이스에 연결해 데이터를 읽는다.
  2. 메시지 큐(message queue), 메시지 브로커(message broker) 등의 중계 시스템에 전송 : 등록된 데이터를 일정한 간격으로 꺼내고 모아서 함께 분산 스토리지에 저장한다.
 
### 웹 브라우저에서의 메시지 배송 : Fluentd, Logstash, 웹 이벤트 트래킹
<img width="400" alt="image" src="https://github.com/led156/TIL/assets/67251510/5ac4b66a-5035-4e7e-b860-99a95451966f">

- ❶ 웹 서버 안에서 메시지를 만들어 배송
  + 자체 개발한 웹 애플리케이션 등에서 주로 사용
  + 전송 효율을 높이기 위해 서버상에서 데이터를 축적해 놓고 나중에 모아서 보내는 경우가 많음.
  + Fluentd, Logstash 같은 서버 상주형 로그 수집 소프트웨어가 주로 사용됨.
    * Fluentd에 의한 메시지 배송
    * 
      <img width="388" alt="image" src="https://github.com/led156/TIL/assets/67251510/11930ab6-1a33-4cff-93e4-7c6f8ee990e5">

      - 분산 스토리지에 데이터를 중계하는 메시지 브로커의 역할로 사용.
        + 원래 메시지 브로커로 설계된 것이 아니기 때문에, 한계 존재
          1. 여러 대로 데이터를 복제할 수 없음 : 노드가 고장 나서 버퍼가 사라진다면 보내지 못한 데이터가 없어짐 (디스크 상 버퍼가 사라지지 않는 한 재전송할 수는 있다.)
          2. 메시지를 일방적으로 발송하는 것밖에 못함 : 외부에서 요청해서 메시지를 꺼낼 수 없음.
          3. 배송에 성공한 메시지는 곧 사라져 버리기 때문에 나중에 다시 송신할 수 없음.
      - 내부에 효율적인 버퍼링 메커니즘을 갖고 있음 : 일정 시간 간격/특정 사이즈에 외부로 데이터를 모아 내보낼 수 있음.
      - 필요에 따라 부분적으로 데이터를 바꾸어 쓰거나 복수의 스토리지에 복사할 수 있음.
        
- ❷ 자바스크립트를 사용하여 웹 브라우저에서 직접 메시지를 보냄 : 웹 이벤트 추적(web event tracking)
  + 사용자 측면에서 HTML 페이지에 태그를 삽입만 하면 되어 각종 액세스 분석 서비스 / 데이터 분석 서비스 등에서 사용됨.
  + 수집된 데이터는 그대로 다른 서버로 전송되거나 API 경유로 함께 취득해, 분산 스토리지에 저장함.

### 모바일 앱으로부터의 메시지 배송 : MBaas, SDK
<img width="391" alt="image" src="https://github.com/led156/TIL/assets/67251510/e8863313-2c24-4e27-b8da-b32790fd699b">

- HTTP 프로토콜을 사용 : 통신 방법만 봤을 때 웹 브라우저와 메시지 배송 방식이 동일.
- ❶ MBaaS 경유의 메시지 배송
  + 모바일 앱에서 서버를 직접 마련하는 것이 아닌 MBaas(Mobile Backend as a Service)라는 백엔드의 각종 서비스를 이용할 수 있음.
  + 백엔드 데이터 저장소에 저장한 데이터를 벌크 형 도구를 사용해 꺼냄
- ❷ SDK에 의한 메시지 배송
  + 모바일 앱에 특화된 액세스 해석 서비스를 통해 이벤트 데이터를 수집
  + 서비스에서 제공되는 모바일 용의 편리한 개발 키트(SDK) 사용
  + 오프라인에서 모바일 앱이 사용될 수도 있으므로 발생한 이벤트는 일단 SDK 내부에 축적되고 온라인 상태가 되었을 때 모아서 보내도록 되어 있음.
- 모바일 회선은 통신이 불안정하고 통신 오류에 따른 메시지 재전송이 여러 번 발생함.
  + 따라서 데이터가 중복될 가능성이 높음. → 특정한 중복 제거의 구조도 필요.

### 디바이스로부터의 메시지 배송 : MQTT
- MQTT(MQ Telemetry Transport)
  <img width="374" alt="image" src="https://github.com/led156/TIL/assets/67251510/7d5aed87-de85-4ac2-a665-054b75589a8f">

  + TCP/IP를 사용하여 데이터를 전송하는 프로토콜의 하나
  + Pub/Sub 형 메시지 배송(Pub/Sub message delievery) 구조 ;채팅 시스템/메시징 앱/푸시 알림등에서 주로 사용
      * Pub : 전달(publish)
      * Sub : 구독(subscription)
- MQTT에서 먼저 관리자에 의해 '토픽(topic)'이 만들어짐.
  + 토픽 : 메시지를 송수신하기 위한 대화방과 같은 것
    * 토픽을 구독하면 메시지가 도착하게 되고, 그 토픽을 전달하면 구독 중인 모든 클라이언트에 보내짐
  + MQTT 브로커(MQTT broker) : 메시지의 교환을 중계하는 서버
  + MQTT 구독자(MQTT subscriber) : 메시지를 수신하는 시스템
- 네트워크에서 분리된 경우에도 나중에 재전송하는 구조가 프로토콜 수준에서 고려됨. (HTTP에선 이런 구조를 스스로 생각해야 하지만, MQTT에선 이미 있고 이를 사용 가능하다)
1. 토픽을 작성하고 이를 구독한다.
2. 각 디바이스가 토픽에 메시지를 전달하는 프로그램을 작성한다.
3. MQTT가 정해진 규칙에 따라 메시지 배송을 한다.

### 메시지 배송의 공통화
- 메시지 배송 방식은 어디에서 데이터를 수집하느냐에 달라짐.
- 클라이언트(client) : 메시지가 처음 생성되는 기기
- 프런트 엔드(frontend) : 생성된 메시지를 먼저 받는 서버
  + 클라이언트와의 통신 프로토콜을 구현해야 함.
  + 공격으로부터 데이터를 보호하기 위해 암호화/사용자 인증을 구현
  + 성능 문제를 해결하기 위해 높은 확장성 필요
+ 메시지 브로커 : 프런트 엔드에서 받은 메시지를 전달 받음.
  + 분산 스토리지에 데이터를 저장



# 4.2. [성능×신뢰성] 메시지 배송의 트레이드 오프
- 클라이언트의 수가 많아지면 스트리밍 형의 메시지 배송의 '성능'과 '신뢰성'을 둘 다 만족하기 어려움.

## 메시지 브로커
- 쓰기의 빈도가 증가해 디스크 성능이 한계에 도달하면, 데이터 저장에 문제가 생김
  + 외부에서 들어오는 메시지 양을 제어할 수 없기 때문에 급격한 양 증가에 대응하기 쉽지 않음.
- 쓰기 성능 한계에 의해 오류가 생기면, 대부분 클라이언트는 메시지를 재성능하려고 함 → 부하만 높아질 뿐임.
- 대량의 메시지를 안정적으로 받기 위해 쓰기 성능이 매우 높고 필요에 따라 쓰기를 높일 수 있는 스토리지가 필요.
  + 분산 스토리지가 이런 성격을 무조건 갖고 있지 않기 때문에 메시지 브로커 도입.
- 메시지 브로커(message broker) : 데이터를 일시적으로 축적하는 중산층 (Apache Kafka, Amazon Kinesis)
  <img width="592" alt="image" src="https://github.com/led156/TIL/assets/67251510/cacc7a15-024c-48bc-85ff-3878479924d6">

### 푸쉬 형과 풀 형
- 푸시 형 : 송신 측의 제어로 데이터를 보내는 방식
- 풀 형 : 수신 측의 주도로 데이터를 가져오는 것
- 이때 메시지 브로커는 데이터의 쓰기 속도를 조정하기 위한 완충 부분, 푸쉬 형에서 풀 형으로 메시지 배송 타이밍을 변환함.
  + 생산자 : 메시지 브로커에 데이터를 넣는(push) 것
  + 소비자 : 메시지 브로커에서 데이터를 꺼내오는(pull) 것
- 메시지 브로커
  + 높은 빈도를 가진 데이터 쓰기에 최적화되어 있음
  + 여러 대 노드에 부하 분산할 수 있음 (뛰어난 확장성)
  + 푸쉬 형 메시지 배송은 메시지 브로커에 집중시키고, 일정한 빈도(=메시지의 양을 조절하는 것)로 꺼낸 데이터를 분산 스토리지에 기록하여 성능 문제 해결
 
### 메시지 라우팅
<img width="591" alt="image" src="https://github.com/led156/TIL/assets/67251510/72987985-0ff3-4939-adad-54c42d4baef1">

- 예시)
  + 100만 대의 디바이스에서 1분마다 100바이트의 메시지를 수신
  + 시스템 전체가 받는 메시지는 초당 1.7만 메시지 (=1.66MB)
  + 초당 1.7만 번 쓰기를 견디는 데이터베이스 준비는 쉽지 않음.
- 스트림 처리(stream processing) : 짧은 간격으로 차례대로 데이터를 꺼내서 처리하는 것
  + 프런트 엔드에서 메시지 브로커에 데이터를 푸쉬하고, '소비자'에서 모아서 가져옴 (1초마다 가져오면 한 번에 1.66MB 데이터양을 가져옴)
- 메시지 브로커에 넣은 데이터는 복수의 다른 소비자에서 읽을 수 있음.
  + 메시지가 복사되어 데이터를 여러 경로로 분기시킬 수 있음 : 메시지 라우팅(message routing)
  + 예시) 메시지 일부를 실시간 장애 감지에 사용하면서 같은 메시지를 장기적인 데이터 분석을 위한 분산 스토리지에 저장하는 것도 가능.
 
## 메시지 배송을 확실하게 실시하는 것은 어렵다
- 모바일 회선과 같이 신뢰성이 낮은 네트워크에서 메시지 중복과 누럭을 어떻게 처리할 지.
  + 중앙에 코디네이터가 존재할 경우 : at most once / at least once
  + 존재하지 않을 경우(중복이 발생)
- 자바스크립트에 의한 데이터 수집은 그다지 신뢰할 수 없음 : 웹페이지를 닫는 것만으로도 쉽게 작동이 중지되기 때문.

|소프트웨어|신뢰성|
|---|---|
|Apache Flume|'at least once' 보장|
|Apache Kafka|'at least once' 보장|
|Logstash|'at least once' 보장|
|Fluentd|옵션으로 'at least once' 보장|

### 1. at most once
- at most once : 메시지는 한 번만 전송된다. 그러나 도중에 전송에 실패해서 사라질 가능성이 있다. (결손)
  + 재전송을 지원하는 시스템에서 이를 보장하기 어렵다.
- 예시) 결손을 피하고자 재전송(retransmission)이 이뤄지는 경우
  + 두 노드 간에 TCP/IP로 메시지를 보낸다.
  + 수신 완료를 나타내는 'ack'가 반환되기 직전에 네트워크 통신이 중단 시.
  + 송신 측에서는 타임아웃을 감지하고 재전송 시작 → 접속이 재개되면 메시지가 재전송됨.
  + 수신 측에서는 메시지를 다받았기 때문에 타임아웃에 의한 통신 종료를 기다리지 않고 데이터 처리를 그냥 진행. ⇒ 중복 발생

### 2. exactly once
- exactly once : 메시지는 손실되거나 중복 없이 한 번만 전달된다
- 코디네이터(coordinator) : 네트워크상에서 분단된 두 개의 노드가 있는 경우, 양쪽의 통신 내용을 보장하기 위해 존재하는 중계기
  + 메시지 송신, 수식 측 정보를 코디네이터에게 전달함으로써 문제 발생시에 코디네이터의 지시에 따라 해결함.
1. 문제점 : 분산 시스템에서 코디네이터가 항상 존재한다고 가정할 수 없다.
   - 코디네이터 통신이 끊기거나, 정지될 경우 이러한 부재의 경우에 어떻게 할 것인지 합의(consensus)가 필요한데, 분산 시스템 설계에서 이는 어려운 문제 중 하나임. (단시간 장애가 발생한다로 주로 결정됨)
2. 문제점 : 코디네이터 판단에만 따르고 있으면 시간이 너무 소요된다.


### 3. at least once
- at least once : 메시지는 확실히 전달된다. 단 같은 것이 여러 번 전달될 가능성이 있다. (중복)
  + 중복 제거(deduplication : 재전송된 메시지를 지움)을 통해 중복이 없는 것처럼 보이게 함.
- 예시) TCP/IP에 의한 네트워크 통신으로 비유
  + IP 통신 : 데이터의 누락, 중복이 일어날 수 있는 신뢰성이 없는 메시지 배송 방식
  + TCP 통신 : 메시지 수신 확인을 위한 'ack' 플래그 도입 (at least once)
    * 메시지 재전송에 의한 중복이 발생하지만, TCP 패킷을 식별하는 시퀀스 번호가 있기 때문에 이를 이용해 중복 제거가 이뤄짐. (메시지 배송 시스템에서 중복 제거는 이용자에게 맡김...)


## 중복 제거는 높은 비용의 오퍼레이션
- 메시지에 중복을 제거하려면 같은 메시지를 과거에 받은 것인지 여부를 판정해야 함
  + TCP에서는 메시지에 시퀀스 번호를 붙이지만, 분산 시스템에 이를 사용하지는 않음 : 번호를 넣음으로써 한 부분에 처리를 집중해야 하는 필요가 생김 → 성능 향상이 어려워짐.
 
### 오프셋을 이용한 중복 제거
- 전송해야 할 데이터에 파일명 등의 이름을 부여하여 메시지 배송
  + 메시지에는 파일 안의 시작 위치(오프셋)를 붙임.
  + 메시지가 중복되어도 같은 파일의 같은 장소를 덮어쓰는 것.
  + 'at least once'가 보장되어 있다면, 언젠가는 데이터 전송이 완료됨.
- 벌크 형 데이터 전송과 같이 데이터양이 고정된 경우에 잘 작동
  + 스트리밍 형식 메시지 배송에서 해당 방식을 사용하지는 않음.
 
### 고유 ID에 의한 중복 제거
- UUID(Universally Unique IDentifier) : 메시지에 고유 ID를 지정하는 방식
- 스트리밍 형 메시지 배송에서 자주 사용되는 방식
- 단, 메시지가 늘어남에 따라 ID가 폭발적으로 증가함
  + 과거 전송된 모든 ID를 기억하는 것은 비현실적, ID를 파기하면 늦게 도착한 메시지가 중복됨
- 따라서 최근에 받은 ID만을 기억해두고, 그보다 늦게 온 메시지의 중복은 허용하도록 함
  + 중복은 대부분 통신 오류로 발생하기 때문에 이것만 제거하면 99% 신뢰도 달성 가능.


### 종단간(End to End)의 신뢰성
- 메시지 배송에 있어서 성능과 신뢰성은 트레이드 오프 관계임
- 빅데이터의 메시지 배송에서는 종종 효율이 중시됨. = 중간 경로에 'at least once'를 보장하지만, '중복 제거는 하지 않는 것'이 표준적 구현.
  + 중복 제거는 종단 간에 실행하지 않으면 의미가 없음.
  + 즉 클라이언트가 생성한 메시지를 최종 도달 지점인 분산 스토리지에 기록하는 단계에서 중복 없는 상태로 해야 함.
  + (단, 메시지 배송의 최종적 신뢰성은 중간 경로의 신뢰성 조합으로 결정됨)
- 스트리밍 형 메시지 배송
  + 클라이언트에서 프런트 엔드, 메시지 브로커와 소비자를 포함한 다수의 요소로 구성됨.
  + 일부분에서 중복 제거가 실현되더라도 다른 곳에서 중복이 발생할 수 있음.
- 중간에 한 부분이라도 'at most once'가 있으면 메시지를 빠뜨릴 가능성이 있고, 'at least once'가 있으면 중복될 수도 있음.
- 신뢰성이 높은 메시지 배송을 실현하려면 중간 경로를 모두 'at least once'로 통일한 후 클라이언트 상에서 모든 메시지에 고유 ID를 포함하도록 하고 경로의 말단에서 중복 제거를 실행해야 함.

### 고유 ID를 사용한 중복 제거의 방법
1. 분산 스토리지로 NoSQL 데이터베이스를 이용하는 것
- Cassandra, Elasticsearch 등은 특성상 데이터를 쓸 때 고유 ID를 지정하게 되어 있어 동일한 ID의 데이터는 덮어씀.
- 따라서 중복이 있더라도 변화가 일어나지 않음 = 중복 제거 실현
2. SQL로 중복을 제거하는 것
```sql
/* DISTINCT */
SELECT DISTINCT unique_id, col1, col2, ... FROM table1;

/* GRPUP BY */
SELECT max(col1) col1, max(col2) col2, ... FROM table1 GROUP BY unique_id;
```
- 보내온 데이터는 그대로 객체 스토리지 등에 저장하고, 읽어 들이는 단계에서 중복을 제거
- 이는 대규모 데이터 처리이므로 메모리에서 실행하는 것은 거의 불가능하고, Hive 같은 배치형 쿼리 엔진에서 실행

## 데이터 수집의 파이프라인
- 데이터 수집의 파이프라인
  + 일련의 프로세스를 거친 다음, 마지막으로 데이터를 구조화해서 열 지향 스토리지로 변환함으로써, 마침내 장기간의 데이터 분석에 적합한 스토리지가 완성됨.
  
<img width="465" alt="image" src="https://github.com/led156/TIL/assets/67251510/9cc1ded5-1f3b-41ca-ba64-f0505349d27e">

- 실제 파이프라인 구현은 요구 사항에 따라 달라짐.
- 쓰기 성능에 불안이 없다면 메시지 브로커는 불필요. 클라이언트/프런트엔드에서 NoSQL 데이터베이스에 직접 데이터를 씀
- 중복이 허용된다면 중복 제거도 허용 가능
- 데이터 집계에 쿼리 엔진을 사용하는 경우, 구조화된 데이터를 열 지향 스토리지 형식으로 객체 스토리지에 저장함.
  + MPP 데이터베이스를 사용하고 있다면 정기적으로 데이터를 로드함.

### 중복을 고려한 시스템 설계
- 스트리밍 형의 메시지 배송에는 중간에 명시적으로 중복 제거 방식을 도입하지 않는 한 항상 중복 가능성이 있음.
  + 신뢰성을 중시할 때는 스트리밍 형 메시지 배송을 피하는 것이 좋음.
  + 과금 데이터처럼 오차가 허용되지 않는 것은 트랜잭션 처리를 지원하는 데이터베이스에 애플리케이션이 직접 기록해야 함.
  + 그런 후 벌크 형의 데이터 전송을 하여 중복/결손을 확실하게 피함.
- 빅데이터 시스템은 높은 성능을 요구하기 때문에, 아주 작은 중복은 무시하는 경향이 있음.
  + 실제로 큰 문제는 없음.
  + 모바일 회선처럼 불안정한 통신 경로를 예외로 하고, 데이터 센터 같이 안정된 회신이면 99% 이상의 신뢰성을 확보함.
  + 이 정도의 오차는 허용한 후, 평송 '멱등한 조작'에 유의하여 '중복이 있어도 문제 되지 않는' 시스템을 설계하도록 한다.

### 메시지 브로커와 신뢰성
- 메시지의 중복/결손은 확률적으로 발생하는 것이 X. 네트워크, 하드웨어의 일시적 장애에 따라 발생하는 설계상의 트레이드 오프.
  + 시스템이 안정적으로 운용될 때는 발생하지 않으므로, 신뢰성을 높이기 위해 간섭을 일으키지 않는 것이 중요함.
- 클라이언트가 송신한 메시지를 받고도 손상시키는 행동은 절대 피할 것.
  + 재전송 구조가 있으면 결손을 피할 수 있지만, 중복 가능성이 커짐.
  + 따라서, 메시지를 먼저 수신하는 프런트 엔드에서 메시지 브로커에 이르는 흐름은 항상 안정된 기록이 가능하도록 확장성 있는 구현을 할 것.
- 메시지 브로커를 사용하면 쓰기 성능이 향상. 또한 후속 처리를 안정화하는 데 도움이 됨.
  + 예를 들어 분산 데이터베이스를 유지 보수로 중지하는 경우에도 메시지 브로커만 움직이고 있으면 데이터 수신에 손상을 입는 일은 없음.
  + 또한 과거의 처리를 소급해서 재시도하고 싶은 경우에도 풀 형의 시스템이면 일정 기간은 몇 번이라도 동이한 데이터를 추출할 수 있음.
- 메시지 브로커는 배송의 안정성은 높이지만, 자체에서 장애가 일어날 수 있음.
  + 따라서 메시지 브로커 안에서 중복이 발생할 가능성이 있기 때문에, 이러한 제약을 지켜보며 '성능'/'신뢰성'을 양립해야 함.

# 4.3. 시계열 데이터의 최적화
- 스트리밍 형의 메시지 배송에서는 '메시지가 도착할 때까지의 시간 지연'이 문제임.

## 프로세스 시간과 이벤트 시간 : 데이터 분석의 대상은 주로 이벤트 시간
- 스마트 폰에서 데이터 수집 시 며칠 정도의 지연을 예측해서 데이터 분석을 고려해야 함.
- 이벤트 시간(event time) : 클라이언트 상에서 메시지가 생성된 시간
- 프로세스 시간(process time) : 서버가 처리하는 시간

## 프로세스 시간에 의한 분할과 문제점 : 최대한 피하고 싶은 풀 스캔(full scan)
- 예를 들어 모바일 앱의 활동 사용자 수를 집계하는 것을 생각했을 때,
  + 늦게 도달하는 데이터가 있다는 것 = 과거 집계 결과가 매일 조금씩 바뀐다는 것.
- 보다 실태에 가까운 집계 결과를 얻기 위해서는 '이벤트 시간'보다 며칠 정도 지난 시점에서 소급해 집계해야 함.

- 한편, 분산 스토리지에 데이터를 넣는 단계에서는 이벤트 시간이 아니라 '프로세스 시간'을 사용함.
  <img width="591" alt="image" src="https://github.com/led156/TIL/assets/67251510/c9c26a2d-3503-4a7b-9001-26a084896928">
- 이 상태에서 과거 특정 일에 발생한 이벤트를 집계하기 위해 수십만 파일 중에서 특정 일의 데이터를 찾는 것은 시간/자원을 낭비하는 처리
  + 데이터가 이벤트 시간으로 정렬되지 않아 모든 데이터를 로드해야만 하기 때문.
- 풀 스캔(full scan) : 다수의 파일을 모두 검색하는 쿼리
  + 시스템 부하를 높이는 요인

## 시계열 인덱스 : 이벤트 시간에 의한 집계의 효율화 ①
1. 시계열 인덱스(time-series index) 생성
   - 이벤트 시간에 대해 인덱스를 만듦.
   - Cassandra는 시계열 인덱스에 대응하는 분산 데이터베이스. (처음부터 이벤트 시간으로 인덱스 된 테이블을 만들 수 있음.
   - 장점 : 매우 짧은 범위의 특정 시간에 맞춘 데이터 집계를 빠르게 실행 가능
   - 단점 : 장기간에 걸쳐서 대량의 데이터를 집계하는 경우에는 분산 데이터베이스가 그다지 효율적이지 않음.
     + 더욱 집계 효율이 높은 열 지향 스토리지를 지속적으로 만들어야 함.

## 조건절 푸쉬다운 : 이벤트 시간에 의한 집계의 효율화 ②
- 열 지향 스토리지에서는 처음 데이터를 정렬할 수 있다.
  <img width="489" alt="image" src="https://github.com/led156/TIL/assets/67251510/5f98ff3e-b87d-4b8e-9e45-316177a57d1d">
- 열 지향 스토리지는 '칼럼 단위의 통계 정보'를 이용하여 최적화가 이뤄짐.
  + 시간이면 각 칼럼의 최솟값과 최댓값 등이 모든 파일에 메타정보로 저장되어 있고, 이 정보를 참고해 어떤 파일의 어떤 부분에 원하는 데이터가 있는지 알수 있다.

2. 조건절 푸시 다운(predicate pushdown) 방법 사용
   - 필요 최소한만의 데이터만을 읽게 하는 최적화 방법.
   - 열 지향 스토리지를 만들 때 읽는 데이터 양을 최소화해, 데이터를 정렬해둠으로써 조건절 푸시다운에 의한 최적화가 작동해 풀 스캔을 피함.
     <img width="444" alt="image" src="https://github.com/led156/TIL/assets/67251510/92625411-425b-4f6d-aa19-9dd58daf0a1b">

## 이벤트 시간에 의한 분할 : 테이블 파티셔닝, 시계열 테이블
- 프로세스 시간으로 파일을 나누는 한, 동일 이벤트 시간 데이터가 다수 파일에 분산됨.
  + 따라서 이벤트 시간을 사용해 테이블을 분할해보자.
 
- 시계열 테이블(time-series table) : 시간을 이용하여 분할된 테이블
  
- <img width="480" alt="image" src="https://github.com/led156/TIL/assets/67251510/1a5e21b8-be5e-4f5d-8f3d-fee677703c0e">

  + 이벤트 발생 시간을 파티션 이름에 포함.

- 해당 방법은 시계열 테이블에 데이터 추가를 어떻게 구현하느냐에 잘 될지의 여부가 달림.
- 새로 도착한 데이터를 새로운 파일로 만드는 것은 잠재적 문제가 있다
  + 과거 이벤트 시간을 갖는 데이터는 극히 드물지만, 몇 년에 걸쳐 보내올 가능성이 있음. = 각 파티션에 조금씩 데이터가 추가됨
  + 결과적으로 분산 스토리지에는 대량의 작은 파일이 있게 되어, 점차 쿼리 성능이 악화됨.
  + → 따라서, 이벤트 시간으로부터 시계열 테이블을 만든다면 작은 데이터를 효율적으로 추가할 수 있는 분산 데이터베이스를 사용하거나 너무 오래된 데이터는 버리는 아이디어가 필요.

### 데이터 마트를 이벤트 시간으로 정렬하기
- 더 좋은 방법 : 데이터 마트만이 이벤트 시간에 의한 정렬을 고려하도록 해두는 것
- 데이터 마트를 만드는 단계에서 이벤트 시간에 의한 정렬을 함.
<img width="480" alt="image" src="https://github.com/led156/TIL/assets/67251510/06ed88c1-2db6-4dfd-8b22-ab499d8f6fe9">


# 4.4. 비구조화 데이터의 분산 스토리지
- NoSQL 데이터베이스의 특징
  + 데이터를 모아서 저장할 수 있다
  + 애플리케이션에서 온라인으로 이용하거나 실시간으로 집계할 수 있다

## [기본 전략] NoSQL 데이터베이스에 의한 데이터 활용
- 빅데이터를 위한 스토리지
  + 확장성, 구조화하지 않은 데이터를 저장할 수 있는 유연성

- 객체 스토리지
  + 장점 : 임의의 파일을 저장할 수 있는 유연성이 요구
  + 단점 :
    * 파일을 교체하기 어렵다.
      - 로그 파일처럼 변경할 일이 없는 것은 괜찮지만, 데이터베이스처럼 수시로 변경하는 용도는 적합하지 않다.
      - → 쓰기 빈도가 높은 데이터는 별도 RDB에 저장하고 정기적으로 스냅샷 하거나 다른 '분산 데이터베이스(distributed database)'에 저장
    * 중요한 데이터는 트랜잭션 처리에 대해 고련된 데이터베이스에 기록하는 것이 원칙
      - 스트리밍 형 메시지 배송은 트랜잭션 처리가 이뤄지지 않음. 확실한 기록 보증이 어려움.
      - 일반적인 RDB에서 충분한 쓰기 성능을 얻지 못 한다면, 분산 데이터베이스를 검토.
    * 저장된 데이터를 집계할 수 있게 되기가지 시간이 걸린다.
      - 열 지향 스토리지로 집계는 고속화되지만, 작성에 시간이 걸린다.
      - 곧바로 활용하고자 할 때는 실시간 집계와 검색에 적합한 데이터 저장소가 필요함.

- 특정 용도에 최적화된 데이터 저장소를 일컬어 'NoSQL 데이터베이스'라 함.
  + 예) 분산 KVS, 와이드 칼럼 스토어, 도큐먼트 스토어, 검색엔진
     
## 분산 KVS : 디스크로의 쓰기 성능을 높이기
<img width="593" alt="image" src="https://github.com/led156/TIL/assets/67251510/9cf41bba-8ce8-4af3-9561-849e362e35b0">

- 모든 (작은) 데이터를 키값 쌍으로 저장
- 데이터에 고유의 키를 지정
  + 값을 클러스터 내의 어느 노드에 배치할지 결정 → 노드 간 부하를 균등하게 분산하고, 노드를 증감 : 클러스터의 성능을 변경 가능
- 가장 간단한 경우 ; 하나의 키에 하나의 값만 할당
  + 키에 여러 값을 할당, 여러 키 조합에 값을 할당 할 수도 있음.

 
### Amazon DynamoDB
- 안정된 읽기 쓰기 성능을 제공하도록 디자인된 분산형 NoSQL 데이터베이스
  + 하나 도는 두 개 키에 연결하는 형태로 임의의 스키마리스 데이터 저장 가능.
  + JSON 같은 중첩 데이터 구조도 취급 가능해 도큐먼트 스토어로도 사용 가능.
- P2P형의 분산 아키텍처
  + 미리 설정한 초 단위의 요청 수에 따라 노드가 증감함
  + → 데이터 읽기/쓰기에 지연이 발생하면 곤란한 애플리케이션에 유용

  
<img width="522" alt="image" src="https://github.com/led156/TIL/assets/67251510/0737684b-3296-42e9-8c08-e9b228d4b03d">

- NoSQL 데이터베이스에 자체적으로 대량의 데이터를 집계하는 기능이 없는 경우가 많음 : 외부로 데이터 추출.
  + RDB와 비교하면 읽기 성능이 높음. → 쿼리 엔진에서 접속해도 성능상 문제가 발생하는 경우가 낮긴 함.
- 데이터 분석을 위해 Amazon EMR/Amazon Redshift에 결합하여 Hive에 의한 배치 처리를 실행하거나 데이터 웨어하우스에 데이터를 전송한다.
- DynamoDB Streams를 사용하면 데이터 변경을 이벤트로 외부에 전송해 실시간 스트림 처리를 할 수 있음.
  + Kinesis Stream : 메시지 브로커

## 와이드 칼럼 스토어 : 구조화 데이터를 분석해서 저장하기
- 분산 KVS를 발전시켜 2개 이상의 임의의 키에 데이터를 저장할 수 있게 한 것.
  + 예) Google Cloud Bigtable, Apache HBase, Apache Cassandra
- 내부적으로 행 키와 칼럼 명의 조합에 대해 값을 저장
- 테이블에 새로운 행을 추가하는 것과 마찬가지로 칼럼도 얼마든지 추가할 수 잇는 구조.
- → 하나에 테이블에 가로와 세로의 2차원 데이터를 쓰도록 한 것
  <img width="552" alt="image" src="https://github.com/led156/TIL/assets/67251510/d6b08da3-923a-4246-a9db-3ccb44bc5ccd">

### Apache Cassandra
- 'CQL'이라는 쿼리 언어가 있음.
- 테이블의 스키마가 결정되어야함 따라서 구조화 데이터만 취급 가능.
  + RDB와 비슷하지만 쿼리 의미에서는 많이 다름. (`INSERT INTO` : 추가 또는 갱신(덮어쓰기, `upsert`)로 동작)
- P2P형의 분산 아키텍처
  + 지정한 키에 의해 결정한 노드에 해당 키와 관련된 모든 값 저장
  + → 다수의 독립적인 키가 있는 경우에 처리 분산 유용
- 예시) 각 사용자가 매일 수십 메시지를 기록하는 메시지 서비스
  + 매일 수십업 레코드가 추가 되는 경우, 사용자 ID를 키로 데이터를 분산.
  + 메시지의 타임스탬프로 레코드를 분리 → 사용자별 타임 라인 구축
  + CQL에서 이런 거대한 테이블을 '복합키(compound key)'를 이용하여 실현함.
- 집계를 위해선 분산된 모든 노드에서 데이터를 모아야함. (데이터 집계에 적합X)
  + Hive, Presto, Spark 등 쿼리 엔진은 모두 Cassandra 로드에 대응하고 있음.
    <img width="595" alt="image" src="https://github.com/led156/TIL/assets/67251510/7f4f9974-d04d-4929-8048-c2b65880e911">


## 도큐먼트 스토어 : 스키마리스 데이터 관리하기
- 와이드 칼럼 스토어는 '성능 향상'을 목표로. 도큐먼트 스토어는 '데이터 처리의 유연성'을 목적으로.
  + JSON처럼 복잡하게 얽힌 스키마리스 데이터를 형태 그대로 저장하고 쿼리를 실행할 수 있게 함.
  + 배열과 인상 배열(맵 형)과 같은 중첩된 데이터 구조에 대해 인덱스를 만들거나 도큐먼트 일부만을 치환하는 식의 쿼리를 쉽게 할 수 있음
    * 분산 KVS도 JSON을 저장할 순 있긴 하지만, 쿼리 처리에 대해 차이가 남.
- 장점 : 스키마를 정하지 않고 저장하는 데 적합함.
  + → 외부에서 들여온 데이터를 저장하는 데 유용 (참고 시스템의 데이터 및 로그 저장)
 
### MongoDB
- 자바스크립트나 각종 프로그래밍 언어를 사용해 데이터를 읽고 쓸 수 있음.
- 성능(간편함)을 우선해 신뢰성을 희생하는 경우가 많음.
- 여러 노드에 데이터를 분산할 수 있지만, 대량 데이터를 집계하는 데 적합하지 않다.
  + 분산이 목적인 경우 쿼리 엔진으로부터 접속하는 등 데이터를 추출할 필요가 있음.
  

## 검색 엔진 : 키워드 검색으로 데이터 검색
- 데이터베이스와는 성격이 다르지만, 저장된 데이터를 쿼리로 찾아낸다는 점에서 유사.
  + 텍스트 데이터/스키마리스 데이터를 집계하는 데 자주 사용됨.
- 역 색인(inverted index)
  + 텍스트에 포함된 단어를 분해하고 어떤 단어가 어떤 레코드에 포함되어 있는가 하는 인덱스를 먼저 만듦 (검색 고속화에 이용)
  + 데이터를 기록하는 시스템 부하/디스크 소비량은 커지지만, 키워드 검색이 훨씬 고속화됨. (없으면 전체 스캔해야 하므로, 검색 효율이 저하됨)
  + 다만, 현재는 SQL로도 정규 표현을 통해 키워드를 찾아낼 수 있다 (나머지는 처리 속도의 문제)
    * 예시) Google BigQuery : 대량의 계산 자원을 이용해 몇 초 만에 빅데이터 전체 스캔이 가능
- 대부분 NoSQL 데이터베이스가 성능 향상을 위해 색인 작성을 제한하는데, 검색 엔진은 색인하므로써 데이터를 찾는 것에 특화됨.
- 결과적으로 검색 엔진은 테이터의 집계에 적합하며, 비정상적인 상태의 감지와 같은 민첩성이 요구되는 용도에서 최근의 데이터를 보기 위해 사용됨.
- 장기적으로 데이터를 축적하기보다는 실시간 집계 시스템의 일부로 이용됨
  + 배송된 데이터를 분산 스토리지에 저장하는 한편, 같은 데이터를 검색 엔진에도 전송하여 실시간성이 높은 데이터 처리를 위해 활용.
    <img width="390" alt="image" src="https://github.com/led156/TIL/assets/67251510/d2875234-0099-45f7-929b-0906727e87c3">

### Elasticsearch
- 검색 엔진 'Elasticsearch' + 로그 수집 'Logstash' + 시각화 'Kibana' = 'ELK 스택'/'Elastic 스택'
- 도큐먼트 스토어와 마찬가지로 JSON 데이터를 저장할 수 있다.
- 모든 필드에 색인이 만들어진다는 특징이 있음. → 도큐먼트 스토어와 비교하면 쓰기의 부하가 큼.
  + 텍스트 데이터에서는 역 색인 구축
- 쓰기 부하가 크기 때문에, 필요에 따라 명시적으로 스키마를 결정해 색인을 무효하는 등의 튜닝이 필요함.
- 자체 쿼리 언어에 의한 고급 집계 기능을 제공함
  + 열 지향 스토리지에도 대응하고 있어 이만으로도 데이터를 집계하기 위한 기반이 됨.
  + 다만 표준 쿼리 언어는 너무 저차원의 언어(?)이므로, kibana 같은 프런트엔드를 쓰거나 프로그램 안에서 호출하여 사용함.
 
### Splunk
- 상용 검색엔진
- 주 데이터 형식 : 비정형 데이터(웹 서버, 네트워크 기기로부터 출력되는 로그 파일/JSON 파일), 텍스트 처리를 해야만 분석할 수 있는 데이터
