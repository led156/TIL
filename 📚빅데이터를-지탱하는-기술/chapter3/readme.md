<img width="471" alt="image" src="https://github.com/led156/TIL/assets/67251510/c0c92183-58fb-4c4f-9b24-881c75e30129">


# 3.1. 대규모 분산 처리의 프레임워크
## 구조화 데이터와 비구조화 데이터
- 스키마(schema) : 테이블의 칼럼 명, 데이터형, 테이블 간의 관계 등을 스키마로 정함.
- 구조화된 데이터(structed data) : 스키마가 명확하게 정의된 데이터.
- 기존 데이터 웨어하우스에는 항상 구조화된 데이터만 축적하는 것이 일반적이었다.
  + 다만, 빅데이터에 항상 SQL로 집계할 수 있는 구조화된 데이터만 있는 것이 아님. (텍스트, 이미지, 동영상 등의 데이터 = 비구조화 데이터(unstructed data))
- 이런 비구조화 데이터를 분산 스토리지 등에 저장하고 분산 시스템에서 처리하는 것이 데이터 레이크의 개념.
  + 데이터를 가공하는 과정에서 스키마를 정의하고, 구조화된 데이터로 변환함으로써 다른 데이터와 마찬가지로 분석할 수 있다.

### 스키마리스 데이터
- 스키마리스 데이터(schemaless data) : 데이터 서식(CSV, JSON, XML)은 정해져 있지만, 칼럼 수나 데이터형을 명확하지 않은 것.
  + NoSQL DB, 데이터 레이크에서 이를 대응하기도 함.
  + 최근 인터넷 데이터 형식으로 JSON 형식을 이용하는 경우가 많은데, JSON은 그대로 저장하고 거기서 필요한 필드만을 추출하는 편이 사용됨.

### 데이터 구조화의 파이프라인
<img width="476" alt="image" src="https://github.com/led156/TIL/assets/67251510/5d68f32b-7298-42aa-bbe9-e266c7f9106c">

- 데이터소스에서 수집된 비구조화 데이터, 스키마리스 데이터는 분산 스토리지에 보존됨. (e.g. 웹 서버 로그 파일, 업무용 데이터베이스에서 추출한 마스터 데이터 등)
- 분산 스토리지에 수집된 데이터를 스키마를 명확하게 한 테이블 형식의 구조화 데이터로 변환한다.
  + 구조화 데이터의 압축률을 높이기 위해 열 지향 스토리지로 저장.
  + 💡 열 지향 스토리지에서 압축률이 좋은 이유
    * 각 열에 대한 데이터를 연속적으로 저장하는데, 이는 같은 열에 속한 데이터가 서로 비슷한 유형 및 패턴을 가질 가능성이 높다는 것을 의미함.
    * 동일한 데이터가 같은 열에 반복적으로 나타날 가능성이 높음.
    * ❗️ 다만, 기존 rdbm(행 지향형)과 달리 일관성(acid)을 보장하지 못함.
- 팩트 테이블 : 시간에 따라 증가하는 구조화 데이터
  + 디멘전 테이블 : 팩트 테이블에 따른 부속 데이터
- 이 단계에서는 테이블을 조인하지 않고, 데이터 마트에 대해 생각하지 않는다. 우선은 데이터를 구조화해서 SQL로 집계 가능한 테이블을 만들도록 함.

### 열 지향 스토리지의 작성
- ⑴MPP 데이터베이스의 경우 제품에 따라 스토리지 형식이 고정되어 있음. 다만 ⑵Hadoop에서는 직접 열 지향 스토리지 형식을 선택하고, 다른 쿼리 엔진에서 그것을 집계할 수 있음.
  + Hadoop에서 사용할 수 있는 열 지향 스토리지 :
    * Apache ORC : 구조화 데이터를 위한 열 지향 스토리지. 처음에 스키마를 정한 후 데이터를 저장
    * Apache Parquet : 스키마리스에 가까운 데이터 구조로 되어 있어 JSON 같이 뒤얽힌 데이터도 그대로 저장할 수 있음.
- 비구조화 데이터를 읽어 열 지향 스토리지로 변환하는 과정에서는 데이터의 가공 및 압축을 위해 많은 컴퓨터 리소스가 필요함 → 따라서 분산 처리 프레임워크(Hadoop, Spark) 도입

## Hadoop
<img width="555" alt="image" src="https://github.com/led156/TIL/assets/67251510/8d2b9403-7bd3-437b-a4c7-9b4e55102b03">

- Hadoop은 단일 소프트웨어가 아니라 분산 시스템을 구성하는 다수의 소프트웨어로 이루어진 집합체.
  + 리소스 관리자(YARN) 상에서 복수의 분산 애플리케이션이 동작하는 구성.
  + 대규모 분산시스템을 구축하기 위한 공통 플랫폼의 역할을 담당.
 
### 분산 시스템의 구성 요소
- HDFS(Hadoop Distributed File System) : 분산 파일 시스템(distributed file system)
- YARN(Yet Another Resource Negotiator) : 리소스 관리자(resource manager)
- MapReduce : 분산 데이터 처리(distributed data processing) 기반
- 모든 분산 시스템이 하둡에 의존하지 않고, 일부만 사용하거나 혹은 이용하지 않는 구성도 있음 (e.g. 분산 파일 시스템은 'HDFS', 리소스 관리자는 'Mesos', 분산 데이터 처리는 'Spark')

### 분산 파일 시스템(HDFS)과 리소스 관리자(YARN)
<img width="599" alt="image" src="https://github.com/led156/TIL/assets/67251510/96046ced-7bcb-431a-a3d3-4a45f2a22049">

- 하둡에서 처리되는 데이터 대부분은 분산 파일 시스템인 HDFS에 저정됨.
  + 네트워크에 연결된 파일 서버와 같은 존재.
  + 다수의 컴퓨터에 파일을 복사하여 중복성을 높인다는 특징이 있음.
- CPU나 메모리 등의 계산 리소스는 리소스 매니저인 YARN에 의해 관리됨.
  + 애플리케이션이 사용하는 CPU 코어와 메모리를 '컨테이너' 단위로 관리함. (OS 수준의 가상화 기술이 아니라, 어떤 호스트에서 어떤 프로세스를 실행시킬 것인지 결정하는 애플리케이션 수준의 기술)
  + 하둡에서 분산 애플리케이션을 실행하면 YARN이 클러스터 전체의 부하를 보고 비어 있는 호스트부터 컨테이너를 할당함.
- 분산 시스템은 많은 계산 리소스를 소비하지만, 호스트 수에 따라 사용할 수 있는 리소스 상한이 결정됨.
  + 한정된 리소스로 다수의 분산 애플리케이션이 동시에 실행되므로 애플리케이션 간 리소스 쟁탈이 발생함.
  + 리소스 관리자는 어느 애플리케이션에, 얼만큼의 리소스를 할당할 지 관리함으로써 모든 애플리케이션이 차질없이 실행되도록 제어함.
- 리소스 관리자를 사용하면 애플리케이션마다 우선순위를 결정할 수 있음
  + 별로 중요하지 않은 배치 처리에는 낮은 우선순위를 부여.

### 분산 데이터 처리(MapReduce) 및 쿼리 엔진(Hive)
<img width="541" alt="image" src="https://github.com/led156/TIL/assets/67251510/0f9907f8-202e-4a5f-8685-3d71deaa8777">

- MapReduce는 임의의 자바 프로그램을 실행시킬 수 있기 때문에, 비구조화 데이터를 가공하는 데 적합함.
- Apache Hive(Hive on MR) : 쿼리를 자동으로 MapReduce 프로그램으로 변환하는 소프트웨어로 개발됨.
  + MapReduce : 대량의 데이터를 배치 처리하기 위한 시스템으로, 한 번 실행시 분산 파일시스템에서 대량의 데이터를 읽을 수 있지만 작은 프로그램을 실행하려면 오버헤드가 너무 큼.
  + Hive는 초기에 MapReduce에 의존하고 있었기 때문에, 시간이 걸리는 배치 처리에 적합하나, 애드 혹 쿼리를 여러 번 실행하는 데는 부적합함.
 
### Hive on Tez
<img width="601" alt="image" src="https://github.com/led156/TIL/assets/67251510/aca33601-3d49-495c-8c18-69732d887c4f">

- Apache Tez : MapReduce 프로그램에서 1회의 MapReduce 스테이지가 끝날 때까지 다음 처리를 진행할 수 없는데, Tez에서는 스테이지의 종료를 기다리지 않고 처리가 끝난 데이터를 차례대로 후속 처리에 전달함으로써 쿼리 전체의 실행 시간을 단축함.
- 현재 Hive는 Tez를 사용해도 동작하게 재작성되어 있음(Hive on Tez). 따라서 기존 MapReduce에 있던 몇 가지 단점을 해소함으로써 고속화를 실현함.

### 대화형 쿼리 엔진(Impala, Presto)
<img width="595" alt="image" src="https://github.com/led156/TIL/assets/67251510/f05a7078-e157-493e-b437-4d2af6bfe43a">

- Hive를 고속화하는 것이 아니라 처음부터 대화형 쿼리 실행만 전문으로 하는 쿼리 엔진 : Apache Impala, Presto
- MapReduce, Tez는 장시간 배치 처리를 가정해 한정된 리소스를 유효하게 활용하도록 설계됨.
  + 대화형 쿼리 엔진으로는 순간 최대 속도를 높이기 위해 모든 오버헤드가 제거되어 사용할 수 있는 리소스를 최대한 활용함.
  + 그 결과, MPP 데이터베이스와 비교해도 손색없는 응답시간을 실현함.

### 정리
- 목적에 따라 성질이 다른 쿼리 엔진(SQL-on-Hadoop)을 구분할 수 있음
  + 대량의 비구조화 데이터를 가공하는 무거운 배치 처리 : Hive. 높은 처리량(Throughtput)으로 리소스를 활용할 수 있음.
  + 완성한 구조화 데이터를 대화식으로 집계할 때 : Impala, Presto. 지연이 적음.
  + MPP 데이터베이스와 비교해 기능적으로 따라잡지 못한 부분❓도 있지만, 분산 스토리지에 저장된 데이터를 신속하게 집계할 수 있는 점에서 우수.

## Spark
- MapReduce보다 더 효율적인 데이터 처리를 실현. Hadoop(Tez)과는 다른 독립적 프로젝트
- 대량의 메모리를 활용하여 고속화를 실현하는 것.
  + MapReduce 개발 시절, 처리 데이터양보다 훨씬 작은 메모리를 사용할 수 밖에 없었음. → 따라서 대부분의 처리를 디스크의 I/O에 사용.
  + 하지만 메모리양이 증가함에 따라, '가능한 한 많은 데이터를 메모리상에 올려, 디스크에는 아무것도 기록하지 않는다'라는 선택이 현실화됨.
    * 이때 비정상 종료되어 휘발되면, 단순히 다시 처리해 중간 데이터를 다시 만들면 된다는 개념.

### MapReduce 대체하기
<img width="595" alt="image" src="https://github.com/led156/TIL/assets/67251510/32bcd79f-8de4-48c9-96a1-2cdfec6e0597">

- 스파크는 하둡을 대체하는 것이 아닌, 맵리듀스를 대체하는 존재임.
  + 그래서 분산 파일 시스템인 HDFS나 리소스 관리자 YARN을 그대로 사용할 수 있다.
  + 하둡을 이용하지 않아도 되며, 분산 스토리지로 Amazon S3나 분산 데이터베이스인 카산드라(cassandra)를 사용하는 것도 가능하다.
- 스파크의 실행은 자바 런타임이 필요하지만, 스파크 상에서 실행되는 데이터 처리는 스크립트 언어를 사용할 수 있음.
  + 자바, 스칼라, 파이썬, R언어
- Spark SQL(SQL로 쿼리실행), Spark Streaming(스트림 처리 수행)
  + 따라서, 대규모 배치 처리뿐만 아니라 대화형 쿼리 실행(SQL)과 실시간 스트림 처리에 이르기까지 널리 이용됨.

# 3.2. 쿼리 엔진
## 데이터 마트 구축의 파이프라인


# 3.3.


